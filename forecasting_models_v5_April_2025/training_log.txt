Starting training of all models at Τετ 09 Απρ 2025 01:48:51 μμ EEST
Models will be saved in /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5
All models will be trained with the new dataset format (default) and --use_stats flag enabled

=====================================================
Training linear model with config: basic
Starting at Τετ 09 Απρ 2025 01:48:51 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type linear                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 
2025-04-09 13:48:51.697039: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:48:51.856693: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:48:52.452894: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:48:52.452977: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:48:52.452987: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:48:55.453091: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:48:56.111046: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:48:56.111069: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:48:56.111217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5110 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building Linear Regression model...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 225)               0         
                                                                 
 dense (Dense)               (None, 1)                 226       
                                                                 
=================================================================
Total params: 226
Trainable params: 226
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 20s - loss: 1.737624/27 [=========================>....] - ETA: 0s - loss: 0.5859 27/27 [==============================] - 1s 8ms/step - loss: 0.5522 - val_loss: 0.1233 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 0s - loss: 0.134627/27 [==============================] - 0s 3ms/step - loss: 0.1662 - val_loss: 0.0154 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 0s - loss: 0.196826/27 [===========================>..] - ETA: 0s - loss: 0.128527/27 [==============================] - 0s 4ms/step - loss: 0.1283 - val_loss: 0.0098 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 0s - loss: 0.068425/27 [==========================>...] - ETA: 0s - loss: 0.119527/27 [==============================] - 0s 4ms/step - loss: 0.1182 - val_loss: 0.0090 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 0s - loss: 0.037021/27 [======================>.......] - ETA: 0s - loss: 0.108427/27 [==============================] - 0s 4ms/step - loss: 0.1117 - val_loss: 0.0094 - lr: 0.0010
Epoch 6/20
 1/27 [>.............................] - ETA: 0s - loss: 0.065123/27 [========================>.....] - ETA: 0s - loss: 0.107127/27 [==============================] - 0s 4ms/step - loss: 0.1083 - val_loss: 0.0090 - lr: 0.0010
Epoch 7/20
 1/27 [>.............................] - ETA: 0s - loss: 0.137523/27 [========================>.....] - ETA: 0s - loss: 0.104127/27 [==============================] - 0s 4ms/step - loss: 0.1030 - val_loss: 0.0086 - lr: 5.0000e-04
Epoch 8/20
 1/27 [>.............................] - ETA: 0s - loss: 0.081826/27 [===========================>..] - ETA: 0s - loss: 0.101927/27 [==============================] - 0s 4ms/step - loss: 0.1016 - val_loss: 0.0087 - lr: 5.0000e-04
Epoch 9/20
 1/27 [>.............................] - ETA: 0s - loss: 0.104224/27 [=========================>....] - ETA: 0s - loss: 0.099227/27 [==============================] - 0s 4ms/step - loss: 0.0983 - val_loss: 0.0086 - lr: 5.0000e-04
Epoch 10/20
 1/27 [>.............................] - ETA: 0s - loss: 0.050222/27 [=======================>......] - ETA: 0s - loss: 0.095627/27 [==============================] - 0s 4ms/step - loss: 0.0964 - val_loss: 0.0086 - lr: 2.5000e-04
Epoch 11/20
 1/27 [>.............................] - ETA: 0s - loss: 0.083521/27 [======================>.......] - ETA: 0s - loss: 0.092627/27 [==============================] - 0s 4ms/step - loss: 0.0951 - val_loss: 0.0084 - lr: 2.5000e-04
Epoch 12/20
 1/27 [>.............................] - ETA: 0s - loss: 0.157521/27 [======================>.......] - ETA: 0s - loss: 0.098927/27 [==============================] - 0s 4ms/step - loss: 0.0949 - val_loss: 0.0084 - lr: 2.5000e-04
Epoch 13/20
 1/27 [>.............................] - ETA: 0s - loss: 0.086125/27 [==========================>...] - ETA: 0s - loss: 0.092027/27 [==============================] - 0s 4ms/step - loss: 0.0934 - val_loss: 0.0084 - lr: 2.5000e-04
Epoch 14/20
 1/27 [>.............................] - ETA: 0s - loss: 0.112725/27 [==========================>...] - ETA: 0s - loss: 0.095027/27 [==============================] - 0s 4ms/step - loss: 0.0923 - val_loss: 0.0083 - lr: 1.2500e-04
Epoch 15/20
 1/27 [>.............................] - ETA: 0s - loss: 0.102322/27 [=======================>......] - ETA: 0s - loss: 0.090827/27 [==============================] - 0s 4ms/step - loss: 0.0916 - val_loss: 0.0083 - lr: 1.2500e-04
Epoch 16/20
 1/27 [>.............................] - ETA: 0s - loss: 0.160323/27 [========================>.....] - ETA: 0s - loss: 0.089727/27 [==============================] - 0s 4ms/step - loss: 0.0909 - val_loss: 0.0084 - lr: 1.2500e-04
Epoch 17/20
 1/27 [>.............................] - ETA: 0s - loss: 0.088222/27 [=======================>......] - ETA: 0s - loss: 0.084527/27 [==============================] - 0s 4ms/step - loss: 0.0906 - val_loss: 0.0085 - lr: 6.2500e-05
1/5 [=====>........................] - ETA: 0s - loss: 0.01085/5 [==============================] - 0s 2ms/step - loss: 0.0244
Test Loss: 0.024407655000686646
Saved model as forecasting_models_v5/model_linear_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for LINEAR model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 63ms/step
Predicted QoE for the next time step: 15075.419504660644

Linear Model Feature Importance:
Traceback (most recent call last):
  File "timeseries_forecasting_models_v5.py", line 889, in <module>
    main()
  File "timeseries_forecasting_models_v5.py", line 886, in main
    print(f"{feature}: {weight[0]:.4f}")
IndexError: invalid index to scalar variable.
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/linear_basic.h5
Completed at Τετ 09 Απρ 2025 01:49:01 μμ EEST
=====================================================

=====================================================
Training linear model with config: with_l1_reg
Starting at Τετ 09 Απρ 2025 01:49:01 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type linear                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --l1_reg 0.01
2025-04-09 13:49:02.302238: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:49:02.449245: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:49:03.041076: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:49:03.041158: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:49:03.041169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:49:05.814967: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:49:06.495509: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:49:06.495533: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:49:06.495665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5152 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building Linear Regression model...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 225)               0         
                                                                 
 dense (Dense)               (None, 1)                 226       
                                                                 
=================================================================
Total params: 226
Trainable params: 226
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 19s - loss: 0.969925/27 [==========================>...] - ETA: 0s - loss: 0.4575 27/27 [==============================] - 1s 8ms/step - loss: 0.4510 - val_loss: 0.2119 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 0s - loss: 0.282826/27 [===========================>..] - ETA: 0s - loss: 0.312727/27 [==============================] - 0s 3ms/step - loss: 0.3122 - val_loss: 0.2266 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 0s - loss: 0.287726/27 [===========================>..] - ETA: 0s - loss: 0.284327/27 [==============================] - 0s 3ms/step - loss: 0.2837 - val_loss: 0.2196 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 0s - loss: 0.289324/27 [=========================>....] - ETA: 0s - loss: 0.266727/27 [==============================] - 0s 4ms/step - loss: 0.2696 - val_loss: 0.2248 - lr: 5.0000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.27555/5 [==============================] - 0s 1ms/step - loss: 0.4835
Test Loss: 0.4834745228290558
Saved model as forecasting_models_v5/model_linear_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for LINEAR model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 64ms/step
Predicted QoE for the next time step: 25716.819092471924

Linear Model Feature Importance:
Traceback (most recent call last):
  File "timeseries_forecasting_models_v5.py", line 889, in <module>
    main()
  File "timeseries_forecasting_models_v5.py", line 886, in main
    print(f"{feature}: {weight[0]:.4f}")
IndexError: invalid index to scalar variable.
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/linear_with_l1_reg.h5
Completed at Τετ 09 Απρ 2025 01:49:10 μμ EEST
=====================================================

=====================================================
Training linear model with config: with_l2_reg
Starting at Τετ 09 Απρ 2025 01:49:10 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type linear                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --l2_reg 0.01
2025-04-09 13:49:11.263301: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:49:11.410736: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:49:12.072931: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:49:12.073022: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:49:12.073033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:49:14.754248: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:49:15.434840: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:49:15.434868: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:49:15.435019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5151 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building Linear Regression model...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 225)               0         
                                                                 
 dense (Dense)               (None, 1)                 226       
                                                                 
=================================================================
Total params: 226
Trainable params: 226
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 20s - loss: 0.888726/27 [===========================>..] - ETA: 0s - loss: 0.2952 27/27 [==============================] - 1s 8ms/step - loss: 0.2943 - val_loss: 0.0797 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 0s - loss: 0.057627/27 [==============================] - 0s 3ms/step - loss: 0.1510 - val_loss: 0.0345 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 0s - loss: 0.173825/27 [==========================>...] - ETA: 0s - loss: 0.137227/27 [==============================] - 0s 4ms/step - loss: 0.1370 - val_loss: 0.0436 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 0s - loss: 0.135323/27 [========================>.....] - ETA: 0s - loss: 0.124027/27 [==============================] - 0s 4ms/step - loss: 0.1311 - val_loss: 0.0341 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 0s - loss: 0.115825/27 [==========================>...] - ETA: 0s - loss: 0.127027/27 [==============================] - 0s 4ms/step - loss: 0.1279 - val_loss: 0.0330 - lr: 0.0010
Epoch 6/20
 1/27 [>.............................] - ETA: 0s - loss: 0.100523/27 [========================>.....] - ETA: 0s - loss: 0.127727/27 [==============================] - 0s 4ms/step - loss: 0.1218 - val_loss: 0.0318 - lr: 0.0010
Epoch 7/20
 1/27 [>.............................] - ETA: 0s - loss: 0.153822/27 [=======================>......] - ETA: 0s - loss: 0.118527/27 [==============================] - 0s 4ms/step - loss: 0.1159 - val_loss: 0.0301 - lr: 0.0010
Epoch 8/20
 1/27 [>.............................] - ETA: 0s - loss: 0.119823/27 [========================>.....] - ETA: 0s - loss: 0.115527/27 [==============================] - 0s 4ms/step - loss: 0.1126 - val_loss: 0.0327 - lr: 0.0010
Epoch 9/20
 1/27 [>.............................] - ETA: 0s - loss: 0.193324/27 [=========================>....] - ETA: 0s - loss: 0.112327/27 [==============================] - 0s 4ms/step - loss: 0.1114 - val_loss: 0.0289 - lr: 0.0010
Epoch 10/20
 1/27 [>.............................] - ETA: 0s - loss: 0.037624/27 [=========================>....] - ETA: 0s - loss: 0.106727/27 [==============================] - 0s 4ms/step - loss: 0.1045 - val_loss: 0.0280 - lr: 0.0010
Epoch 11/20
 1/27 [>.............................] - ETA: 0s - loss: 0.044024/27 [=========================>....] - ETA: 0s - loss: 0.098027/27 [==============================] - 0s 4ms/step - loss: 0.1014 - val_loss: 0.0309 - lr: 0.0010
Epoch 12/20
 1/27 [>.............................] - ETA: 0s - loss: 0.089521/27 [======================>.......] - ETA: 0s - loss: 0.100527/27 [==============================] - 0s 4ms/step - loss: 0.0977 - val_loss: 0.0281 - lr: 0.0010
Epoch 13/20
 1/27 [>.............................] - ETA: 0s - loss: 0.090124/27 [=========================>....] - ETA: 0s - loss: 0.096227/27 [==============================] - 0s 4ms/step - loss: 0.0953 - val_loss: 0.0270 - lr: 5.0000e-04
Epoch 14/20
 1/27 [>.............................] - ETA: 0s - loss: 0.093223/27 [========================>.....] - ETA: 0s - loss: 0.089727/27 [==============================] - 0s 4ms/step - loss: 0.0943 - val_loss: 0.0260 - lr: 5.0000e-04
Epoch 15/20
 1/27 [>.............................] - ETA: 0s - loss: 0.072524/27 [=========================>....] - ETA: 0s - loss: 0.094827/27 [==============================] - 0s 4ms/step - loss: 0.0946 - val_loss: 0.0288 - lr: 5.0000e-04
Epoch 16/20
 1/27 [>.............................] - ETA: 0s - loss: 0.096925/27 [==========================>...] - ETA: 0s - loss: 0.092527/27 [==============================] - 0s 4ms/step - loss: 0.0916 - val_loss: 0.0265 - lr: 5.0000e-04
Epoch 17/20
 1/27 [>.............................] - ETA: 0s - loss: 0.095222/27 [=======================>......] - ETA: 0s - loss: 0.091327/27 [==============================] - 0s 4ms/step - loss: 0.0902 - val_loss: 0.0259 - lr: 2.5000e-04
Epoch 18/20
 1/27 [>.............................] - ETA: 0s - loss: 0.100522/27 [=======================>......] - ETA: 0s - loss: 0.086827/27 [==============================] - 0s 4ms/step - loss: 0.0903 - val_loss: 0.0263 - lr: 2.5000e-04
Epoch 19/20
 1/27 [>.............................] - ETA: 0s - loss: 0.076323/27 [========================>.....] - ETA: 0s - loss: 0.088727/27 [==============================] - 0s 4ms/step - loss: 0.0890 - val_loss: 0.0259 - lr: 1.2500e-04
Epoch 20/20
 1/27 [>.............................] - ETA: 0s - loss: 0.057920/27 [=====================>........] - ETA: 0s - loss: 0.089427/27 [==============================] - 0s 5ms/step - loss: 0.0887 - val_loss: 0.0256 - lr: 1.2500e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.02875/5 [==============================] - 0s 2ms/step - loss: 0.0257
Test Loss: 0.025651898235082626
Saved model as forecasting_models_v5/model_linear_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for LINEAR model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 66ms/step
Predicted QoE for the next time step: 37024.48695967163

Linear Model Feature Importance:
Traceback (most recent call last):
  File "timeseries_forecasting_models_v5.py", line 889, in <module>
    main()
  File "timeseries_forecasting_models_v5.py", line 886, in main
    print(f"{feature}: {weight[0]:.4f}")
IndexError: invalid index to scalar variable.
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/linear_with_l2_reg.h5
Completed at Τετ 09 Απρ 2025 01:49:21 μμ EEST
=====================================================

=====================================================
Training linear model with config: with_elastic_net
Starting at Τετ 09 Απρ 2025 01:49:21 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type linear                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --l1_reg 0.005 --l2_reg 0.005
2025-04-09 13:49:22.010231: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:49:22.165046: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:49:22.758944: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:49:22.759028: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:49:22.759038: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:49:25.462521: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:49:26.147619: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:49:26.147646: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:49:26.147831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5127 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building Linear Regression model...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 225)               0         
                                                                 
 dense (Dense)               (None, 1)                 226       
                                                                 
=================================================================
Total params: 226
Trainable params: 226
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 21s - loss: 0.637722/27 [=======================>......] - ETA: 0s - loss: 0.3510 27/27 [==============================] - 1s 9ms/step - loss: 0.3349 - val_loss: 0.2108 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 0s - loss: 0.197123/27 [========================>.....] - ETA: 0s - loss: 0.238427/27 [==============================] - 0s 4ms/step - loss: 0.2369 - val_loss: 0.1232 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 0s - loss: 0.227522/27 [=======================>......] - ETA: 0s - loss: 0.214227/27 [==============================] - 0s 4ms/step - loss: 0.2169 - val_loss: 0.1080 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 0s - loss: 0.195021/27 [======================>.......] - ETA: 0s - loss: 0.202727/27 [==============================] - 0s 4ms/step - loss: 0.2046 - val_loss: 0.1038 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 0s - loss: 0.214322/27 [=======================>......] - ETA: 0s - loss: 0.194127/27 [==============================] - 0s 4ms/step - loss: 0.1908 - val_loss: 0.1010 - lr: 0.0010
Epoch 6/20
 1/27 [>.............................] - ETA: 0s - loss: 0.157925/27 [==========================>...] - ETA: 0s - loss: 0.183827/27 [==============================] - 0s 4ms/step - loss: 0.1829 - val_loss: 0.0966 - lr: 0.0010
Epoch 7/20
 1/27 [>.............................] - ETA: 0s - loss: 0.181522/27 [=======================>......] - ETA: 0s - loss: 0.169727/27 [==============================] - 0s 4ms/step - loss: 0.1743 - val_loss: 0.0961 - lr: 0.0010
Epoch 8/20
 1/27 [>.............................] - ETA: 0s - loss: 0.138817/27 [=================>............] - ETA: 0s - loss: 0.172827/27 [==============================] - 0s 4ms/step - loss: 0.1717 - val_loss: 0.0888 - lr: 0.0010
Epoch 9/20
 1/27 [>.............................] - ETA: 0s - loss: 0.125224/27 [=========================>....] - ETA: 0s - loss: 0.162827/27 [==============================] - 0s 4ms/step - loss: 0.1623 - val_loss: 0.0858 - lr: 0.0010
Epoch 10/20
 1/27 [>.............................] - ETA: 0s - loss: 0.195021/27 [======================>.......] - ETA: 0s - loss: 0.148427/27 [==============================] - 0s 4ms/step - loss: 0.1545 - val_loss: 0.0828 - lr: 0.0010
Epoch 11/20
 1/27 [>.............................] - ETA: 0s - loss: 0.151525/27 [==========================>...] - ETA: 0s - loss: 0.150027/27 [==============================] - 0s 4ms/step - loss: 0.1501 - val_loss: 0.0810 - lr: 0.0010
Epoch 12/20
 1/27 [>.............................] - ETA: 0s - loss: 0.149021/27 [======================>.......] - ETA: 0s - loss: 0.143327/27 [==============================] - 0s 4ms/step - loss: 0.1440 - val_loss: 0.0770 - lr: 0.0010
Epoch 13/20
 1/27 [>.............................] - ETA: 0s - loss: 0.099823/27 [========================>.....] - ETA: 0s - loss: 0.146027/27 [==============================] - 0s 4ms/step - loss: 0.1413 - val_loss: 0.0744 - lr: 0.0010
Epoch 14/20
 1/27 [>.............................] - ETA: 0s - loss: 0.183622/27 [=======================>......] - ETA: 0s - loss: 0.139627/27 [==============================] - 0s 4ms/step - loss: 0.1368 - val_loss: 0.0712 - lr: 0.0010
Epoch 15/20
 1/27 [>.............................] - ETA: 0s - loss: 0.112321/27 [======================>.......] - ETA: 0s - loss: 0.134227/27 [==============================] - 0s 4ms/step - loss: 0.1337 - val_loss: 0.0699 - lr: 0.0010
Epoch 16/20
 1/27 [>.............................] - ETA: 0s - loss: 0.134422/27 [=======================>......] - ETA: 0s - loss: 0.129027/27 [==============================] - 0s 4ms/step - loss: 0.1293 - val_loss: 0.0682 - lr: 0.0010
Epoch 17/20
 1/27 [>.............................] - ETA: 0s - loss: 0.094023/27 [========================>.....] - ETA: 0s - loss: 0.125227/27 [==============================] - 0s 4ms/step - loss: 0.1246 - val_loss: 0.0666 - lr: 0.0010
Epoch 18/20
 1/27 [>.............................] - ETA: 0s - loss: 0.085321/27 [======================>.......] - ETA: 0s - loss: 0.122927/27 [==============================] - 0s 4ms/step - loss: 0.1215 - val_loss: 0.0625 - lr: 0.0010
Epoch 19/20
 1/27 [>.............................] - ETA: 0s - loss: 0.092821/27 [======================>.......] - ETA: 0s - loss: 0.118327/27 [==============================] - 0s 4ms/step - loss: 0.1210 - val_loss: 0.0653 - lr: 0.0010
Epoch 20/20
 1/27 [>.............................] - ETA: 0s - loss: 0.125722/27 [=======================>......] - ETA: 0s - loss: 0.118127/27 [==============================] - 0s 4ms/step - loss: 0.1183 - val_loss: 0.0643 - lr: 0.0010
1/5 [=====>........................] - ETA: 0s - loss: 0.07655/5 [==============================] - 0s 2ms/step - loss: 0.0829
Test Loss: 0.08289490640163422
Saved model as forecasting_models_v5/model_linear_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for LINEAR model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 65ms/step
Predicted QoE for the next time step: 29071.33309051575

Linear Model Feature Importance:
Traceback (most recent call last):
  File "timeseries_forecasting_models_v5.py", line 889, in <module>
    main()
  File "timeseries_forecasting_models_v5.py", line 886, in main
    print(f"{feature}: {weight[0]:.4f}")
IndexError: invalid index to scalar variable.
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/linear_with_elastic_net.h5
Completed at Τετ 09 Απρ 2025 01:49:32 μμ EEST
=====================================================

=====================================================
Training dnn model with config: basic
Starting at Τετ 09 Απρ 2025 01:49:32 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type dnn                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 
2025-04-09 13:49:32.875743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:49:33.020677: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:49:33.613521: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:49:33.613612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:49:33.613622: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:49:36.500544: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:49:37.189810: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:49:37.189834: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:49:37.189958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5143 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building Simple DNN model...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 225)               0         
                                                                 
 dense (Dense)               (None, 64)                14464     
                                                                 
 dropout (Dropout)           (None, 64)                0         
                                                                 
 dense_1 (Dense)             (None, 32)                2080      
                                                                 
 dropout_1 (Dropout)         (None, 32)                0         
                                                                 
 dense_2 (Dense)             (None, 1)                 33        
                                                                 
=================================================================
Total params: 16,577
Trainable params: 16,577
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 23s - loss: 0.295418/27 [===================>..........] - ETA: 0s - loss: 0.1320 27/27 [==============================] - 1s 10ms/step - loss: 0.1159 - val_loss: 0.0106 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 0s - loss: 0.036220/27 [=====================>........] - ETA: 0s - loss: 0.071927/27 [==============================] - 0s 4ms/step - loss: 0.0718 - val_loss: 0.0198 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 0s - loss: 0.027518/27 [===================>..........] - ETA: 0s - loss: 0.050027/27 [==============================] - 0s 5ms/step - loss: 0.0521 - val_loss: 0.0069 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 0s - loss: 0.071718/27 [===================>..........] - ETA: 0s - loss: 0.056127/27 [==============================] - 0s 5ms/step - loss: 0.0538 - val_loss: 0.0114 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 0s - loss: 0.059717/27 [=================>............] - ETA: 0s - loss: 0.056127/27 [==============================] - 0s 5ms/step - loss: 0.0532 - val_loss: 0.0114 - lr: 0.0010
Epoch 6/20
 1/27 [>.............................] - ETA: 0s - loss: 0.045716/27 [================>.............] - ETA: 0s - loss: 0.047327/27 [==============================] - 0s 5ms/step - loss: 0.0466 - val_loss: 0.0061 - lr: 5.0000e-04
Epoch 7/20
 1/27 [>.............................] - ETA: 0s - loss: 0.030318/27 [===================>..........] - ETA: 0s - loss: 0.051827/27 [==============================] - 0s 5ms/step - loss: 0.0487 - val_loss: 0.0126 - lr: 5.0000e-04
Epoch 8/20
 1/27 [>.............................] - ETA: 0s - loss: 0.042617/27 [=================>............] - ETA: 0s - loss: 0.045927/27 [==============================] - 0s 5ms/step - loss: 0.0483 - val_loss: 0.0109 - lr: 5.0000e-04
Epoch 9/20
 1/27 [>.............................] - ETA: 0s - loss: 0.032916/27 [================>.............] - ETA: 0s - loss: 0.040327/27 [==============================] - 0s 6ms/step - loss: 0.0456 - val_loss: 0.0107 - lr: 2.5000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.01265/5 [==============================] - 0s 3ms/step - loss: 0.0303
Test Loss: 0.03026186302304268
Saved model as forecasting_models_v5/model_dnn_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for DNN model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 80ms/step
Predicted QoE for the next time step: 16263.59096763214
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/dnn_basic.h5
Completed at Τετ 09 Απρ 2025 01:49:42 μμ EEST
=====================================================

=====================================================
Training dnn model with config: deep
Starting at Τετ 09 Απρ 2025 01:49:42 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type dnn                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --hidden_layers 128,64,32
2025-04-09 13:49:42.983403: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:49:43.140233: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:49:43.793974: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:49:43.794072: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:49:43.794083: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:49:46.552712: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:49:47.254707: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:49:47.254731: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:49:47.254884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5140 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building Simple DNN model...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 225)               0         
                                                                 
 dense (Dense)               (None, 128)               28928     
                                                                 
 dropout (Dropout)           (None, 128)               0         
                                                                 
 dense_1 (Dense)             (None, 64)                8256      
                                                                 
 dropout_1 (Dropout)         (None, 64)                0         
                                                                 
 dense_2 (Dense)             (None, 32)                2080      
                                                                 
 dropout_2 (Dropout)         (None, 32)                0         
                                                                 
 dense_3 (Dense)             (None, 1)                 33        
                                                                 
=================================================================
Total params: 39,297
Trainable params: 39,297
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 24s - loss: 0.219416/27 [================>.............] - ETA: 0s - loss: 0.1193 27/27 [==============================] - 1s 11ms/step - loss: 0.0959 - val_loss: 0.0194 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 0s - loss: 0.054917/27 [=================>............] - ETA: 0s - loss: 0.060927/27 [==============================] - 0s 5ms/step - loss: 0.0573 - val_loss: 0.0292 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 0s - loss: 0.068516/27 [================>.............] - ETA: 0s - loss: 0.060527/27 [==============================] - 0s 5ms/step - loss: 0.0605 - val_loss: 0.0307 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 0s - loss: 0.079414/27 [==============>...............] - ETA: 0s - loss: 0.056227/27 [==============================] - ETA: 0s - loss: 0.052427/27 [==============================] - 0s 6ms/step - loss: 0.0524 - val_loss: 0.0282 - lr: 5.0000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.02665/5 [==============================] - 0s 3ms/step - loss: 0.0364
Test Loss: 0.03641466051340103
Saved model as forecasting_models_v5/model_dnn_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for DNN model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 82ms/step
Predicted QoE for the next time step: 24465.13875433258
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/dnn_deep.h5
Completed at Τετ 09 Απρ 2025 01:49:52 μμ EEST
=====================================================

=====================================================
Training dnn model with config: with_elu
Starting at Τετ 09 Απρ 2025 01:49:52 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type dnn                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --activation elu
2025-04-09 13:49:52.588518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:49:52.772850: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:49:53.450574: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:49:53.450661: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:49:53.450672: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:49:56.160923: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:49:56.833047: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:49:56.833072: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:49:56.833223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4995 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building Simple DNN model...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 225)               0         
                                                                 
 dense (Dense)               (None, 64)                14464     
                                                                 
 dropout (Dropout)           (None, 64)                0         
                                                                 
 dense_1 (Dense)             (None, 32)                2080      
                                                                 
 dropout_1 (Dropout)         (None, 32)                0         
                                                                 
 dense_2 (Dense)             (None, 1)                 33        
                                                                 
=================================================================
Total params: 16,577
Trainable params: 16,577
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 25s - loss: 0.556516/27 [================>.............] - ETA: 0s - loss: 0.2456 27/27 [==============================] - 1s 12ms/step - loss: 0.2075 - val_loss: 0.0044 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 0s - loss: 0.052416/27 [================>.............] - ETA: 0s - loss: 0.119927/27 [==============================] - 0s 5ms/step - loss: 0.1185 - val_loss: 0.0072 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 0s - loss: 0.171516/27 [================>.............] - ETA: 0s - loss: 0.114727/27 [==============================] - 0s 5ms/step - loss: 0.1050 - val_loss: 0.0044 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 0s - loss: 0.118817/27 [=================>............] - ETA: 0s - loss: 0.089127/27 [==============================] - 0s 5ms/step - loss: 0.0879 - val_loss: 0.0026 - lr: 5.0000e-04
Epoch 5/20
 1/27 [>.............................] - ETA: 0s - loss: 0.067217/27 [=================>............] - ETA: 0s - loss: 0.080327/27 [==============================] - 0s 5ms/step - loss: 0.0768 - val_loss: 0.0051 - lr: 5.0000e-04
Epoch 6/20
 1/27 [>.............................] - ETA: 0s - loss: 0.065815/27 [===============>..............] - ETA: 0s - loss: 0.079827/27 [==============================] - 0s 5ms/step - loss: 0.0731 - val_loss: 0.0038 - lr: 5.0000e-04
Epoch 7/20
 1/27 [>.............................] - ETA: 0s - loss: 0.047517/27 [=================>............] - ETA: 0s - loss: 0.070627/27 [==============================] - 0s 5ms/step - loss: 0.0704 - val_loss: 0.0052 - lr: 2.5000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.00445/5 [==============================] - 0s 2ms/step - loss: 0.0038
Test Loss: 0.0038097442593425512
Saved model as forecasting_models_v5/model_dnn_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for DNN model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 82ms/step
Predicted QoE for the next time step: -2378.0071029986952
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/dnn_with_elu.h5
Completed at Τετ 09 Απρ 2025 01:50:02 μμ EEST
=====================================================

=====================================================
Training dnn model with config: with_high_dropout
Starting at Τετ 09 Απρ 2025 01:50:02 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type dnn                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --dropout_rate 0.4
2025-04-09 13:50:02.532244: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:50:02.694359: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:50:03.305180: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:50:03.305279: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:50:03.305293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:50:06.087277: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:50:06.773433: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:50:06.773457: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:50:06.773618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4999 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building Simple DNN model...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 225)               0         
                                                                 
 dense (Dense)               (None, 64)                14464     
                                                                 
 dropout (Dropout)           (None, 64)                0         
                                                                 
 dense_1 (Dense)             (None, 32)                2080      
                                                                 
 dropout_1 (Dropout)         (None, 32)                0         
                                                                 
 dense_2 (Dense)             (None, 1)                 33        
                                                                 
=================================================================
Total params: 16,577
Trainable params: 16,577
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 22s - loss: 0.459219/27 [====================>.........] - ETA: 0s - loss: 0.2190 27/27 [==============================] - 1s 10ms/step - loss: 0.1874 - val_loss: 0.0371 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 0s - loss: 0.117317/27 [=================>............] - ETA: 0s - loss: 0.100727/27 [==============================] - 0s 5ms/step - loss: 0.0919 - val_loss: 0.0194 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 0s - loss: 0.071518/27 [===================>..........] - ETA: 0s - loss: 0.077227/27 [==============================] - 0s 5ms/step - loss: 0.0774 - val_loss: 0.0345 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 0s - loss: 0.069216/27 [================>.............] - ETA: 0s - loss: 0.073527/27 [==============================] - 0s 5ms/step - loss: 0.0720 - val_loss: 0.0313 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 0s - loss: 0.048914/27 [==============>...............] - ETA: 0s - loss: 0.077127/27 [==============================] - 0s 5ms/step - loss: 0.0738 - val_loss: 0.0431 - lr: 5.0000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.01735/5 [==============================] - 0s 2ms/step - loss: 0.0086
Test Loss: 0.008584861643612385
Saved model as forecasting_models_v5/model_dnn_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for DNN model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 80ms/step
Predicted QoE for the next time step: 7843.461700214996
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/dnn_with_high_dropout.h5
Completed at Τετ 09 Απρ 2025 01:50:11 μμ EEST
=====================================================

=====================================================
Training lstm model with config: basic
Starting at Τετ 09 Απρ 2025 01:50:11 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type lstm                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --attention_units 128
2025-04-09 13:50:12.020659: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:50:12.179306: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:50:12.758959: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:50:12.759044: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:50:12.759059: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:50:15.468492: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:50:16.130941: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:50:16.130965: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:50:16.131125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4999 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building LSTM model with self-attention...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 5, 50)             19200     
                                                                 
 lstm_1 (LSTM)               (None, 5, 50)             20200     
                                                                 
 self_attention (SelfAttenti  (None, 50)               6656      
 on)                                                             
                                                                 
 dense (Dense)               (None, 25)                1275      
                                                                 
 dense_1 (Dense)             (None, 1)                 26        
                                                                 
=================================================================
Total params: 47,357
Trainable params: 47,357
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 1:57 - loss: 0.3883 3/27 [==>...........................] - ETA: 1s - loss: 0.3061   5/27 [====>.........................] - ETA: 1s - loss: 0.2750 6/27 [=====>........................] - ETA: 1s - loss: 0.2602 7/27 [======>.......................] - ETA: 0s - loss: 0.2464 9/27 [=========>....................] - ETA: 0s - loss: 0.224111/27 [===========>..................] - ETA: 0s - loss: 0.200813/27 [=============>................] - ETA: 0s - loss: 0.181114/27 [==============>...............] - ETA: 0s - loss: 0.172815/27 [===============>..............] - ETA: 0s - loss: 0.168117/27 [=================>............] - ETA: 0s - loss: 0.155718/27 [===================>..........] - ETA: 0s - loss: 0.149820/27 [=====================>........] - ETA: 0s - loss: 0.138822/27 [=======================>......] - ETA: 0s - loss: 0.131023/27 [========================>.....] - ETA: 0s - loss: 0.126524/27 [=========================>....] - ETA: 0s - loss: 0.123525/27 [==========================>...] - ETA: 0s - loss: 0.120326/27 [===========================>..] - ETA: 0s - loss: 0.117027/27 [==============================] - 6s 74ms/step - loss: 0.1168 - val_loss: 0.0152 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0567 2/27 [=>............................] - ETA: 1s - loss: 0.0480 4/27 [===>..........................] - ETA: 1s - loss: 0.0405 6/27 [=====>........................] - ETA: 1s - loss: 0.0429 8/27 [=======>......................] - ETA: 0s - loss: 0.0388 9/27 [=========>....................] - ETA: 0s - loss: 0.036211/27 [===========>..................] - ETA: 0s - loss: 0.034213/27 [=============>................] - ETA: 0s - loss: 0.034615/27 [===============>..............] - ETA: 0s - loss: 0.035516/27 [================>.............] - ETA: 0s - loss: 0.034417/27 [=================>............] - ETA: 0s - loss: 0.033519/27 [====================>.........] - ETA: 0s - loss: 0.034620/27 [=====================>........] - ETA: 0s - loss: 0.036621/27 [======================>.......] - ETA: 0s - loss: 0.037422/27 [=======================>......] - ETA: 0s - loss: 0.036923/27 [========================>.....] - ETA: 0s - loss: 0.036424/27 [=========================>....] - ETA: 0s - loss: 0.036925/27 [==========================>...] - ETA: 0s - loss: 0.037026/27 [===========================>..] - ETA: 0s - loss: 0.037627/27 [==============================] - 1s 54ms/step - loss: 0.0379 - val_loss: 0.0021 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0372 2/27 [=>............................] - ETA: 1s - loss: 0.0380 3/27 [==>...........................] - ETA: 1s - loss: 0.0422 5/27 [====>.........................] - ETA: 1s - loss: 0.0372 6/27 [=====>........................] - ETA: 1s - loss: 0.0400 7/27 [======>.......................] - ETA: 1s - loss: 0.0396 9/27 [=========>....................] - ETA: 0s - loss: 0.039511/27 [===========>..................] - ETA: 0s - loss: 0.037412/27 [============>.................] - ETA: 0s - loss: 0.035814/27 [==============>...............] - ETA: 0s - loss: 0.036615/27 [===============>..............] - ETA: 0s - loss: 0.036016/27 [================>.............] - ETA: 0s - loss: 0.035617/27 [=================>............] - ETA: 0s - loss: 0.035319/27 [====================>.........] - ETA: 0s - loss: 0.035320/27 [=====================>........] - ETA: 0s - loss: 0.035421/27 [======================>.......] - ETA: 0s - loss: 0.034922/27 [=======================>......] - ETA: 0s - loss: 0.034923/27 [========================>.....] - ETA: 0s - loss: 0.034824/27 [=========================>....] - ETA: 0s - loss: 0.034925/27 [==========================>...] - ETA: 0s - loss: 0.034726/27 [===========================>..] - ETA: 0s - loss: 0.035327/27 [==============================] - ETA: 0s - loss: 0.035527/27 [==============================] - 2s 56ms/step - loss: 0.0355 - val_loss: 7.3138e-04 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0675 2/27 [=>............................] - ETA: 1s - loss: 0.0451 3/27 [==>...........................] - ETA: 1s - loss: 0.0383 4/27 [===>..........................] - ETA: 1s - loss: 0.0366 5/27 [====>.........................] - ETA: 1s - loss: 0.0399 6/27 [=====>........................] - ETA: 1s - loss: 0.0371 7/27 [======>.......................] - ETA: 1s - loss: 0.0369 8/27 [=======>......................] - ETA: 1s - loss: 0.0389 9/27 [=========>....................] - ETA: 0s - loss: 0.038311/27 [===========>..................] - ETA: 0s - loss: 0.038712/27 [============>.................] - ETA: 0s - loss: 0.039513/27 [=============>................] - ETA: 0s - loss: 0.037415/27 [===============>..............] - ETA: 0s - loss: 0.037717/27 [=================>............] - ETA: 0s - loss: 0.040018/27 [===================>..........] - ETA: 0s - loss: 0.040019/27 [====================>.........] - ETA: 0s - loss: 0.038921/27 [======================>.......] - ETA: 0s - loss: 0.038123/27 [========================>.....] - ETA: 0s - loss: 0.036925/27 [==========================>...] - ETA: 0s - loss: 0.036626/27 [===========================>..] - ETA: 0s - loss: 0.036227/27 [==============================] - ETA: 0s - loss: 0.036227/27 [==============================] - 1s 54ms/step - loss: 0.0362 - val_loss: 0.0058 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0644 2/27 [=>............................] - ETA: 1s - loss: 0.0572 3/27 [==>...........................] - ETA: 1s - loss: 0.0485 4/27 [===>..........................] - ETA: 1s - loss: 0.0453 5/27 [====>.........................] - ETA: 1s - loss: 0.0441 6/27 [=====>........................] - ETA: 1s - loss: 0.0409 7/27 [======>.......................] - ETA: 1s - loss: 0.0408 9/27 [=========>....................] - ETA: 0s - loss: 0.040311/27 [===========>..................] - ETA: 0s - loss: 0.040313/27 [=============>................] - ETA: 0s - loss: 0.039115/27 [===============>..............] - ETA: 0s - loss: 0.036917/27 [=================>............] - ETA: 0s - loss: 0.034619/27 [====================>.........] - ETA: 0s - loss: 0.035220/27 [=====================>........] - ETA: 0s - loss: 0.034922/27 [=======================>......] - ETA: 0s - loss: 0.034823/27 [========================>.....] - ETA: 0s - loss: 0.034824/27 [=========================>....] - ETA: 0s - loss: 0.034526/27 [===========================>..] - ETA: 0s - loss: 0.034427/27 [==============================] - 1s 54ms/step - loss: 0.0343 - val_loss: 7.5937e-04 - lr: 0.0010
Epoch 6/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0312 2/27 [=>............................] - ETA: 1s - loss: 0.0298 3/27 [==>...........................] - ETA: 1s - loss: 0.0289 5/27 [====>.........................] - ETA: 1s - loss: 0.0307 7/27 [======>.......................] - ETA: 0s - loss: 0.0321 8/27 [=======>......................] - ETA: 0s - loss: 0.0348 9/27 [=========>....................] - ETA: 0s - loss: 0.034611/27 [===========>..................] - ETA: 0s - loss: 0.032812/27 [============>.................] - ETA: 0s - loss: 0.034213/27 [=============>................] - ETA: 0s - loss: 0.032915/27 [===============>..............] - ETA: 0s - loss: 0.032117/27 [=================>............] - ETA: 0s - loss: 0.032619/27 [====================>.........] - ETA: 0s - loss: 0.031721/27 [======================>.......] - ETA: 0s - loss: 0.032323/27 [========================>.....] - ETA: 0s - loss: 0.033024/27 [=========================>....] - ETA: 0s - loss: 0.033725/27 [==========================>...] - ETA: 0s - loss: 0.033326/27 [===========================>..] - ETA: 0s - loss: 0.032927/27 [==============================] - ETA: 0s - loss: 0.033127/27 [==============================] - 1s 56ms/step - loss: 0.0331 - val_loss: 7.5241e-04 - lr: 5.0000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.00105/5 [==============================] - 0s 9ms/step - loss: 0.0015
Test Loss: 0.0014899304369464517
Saved model as forecasting_models_v5/model_lstm_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for LSTM model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 507ms/step
Predicted QoE for the next time step: 94.62122232284784
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/lstm_basic.h5
Completed at Τετ 09 Απρ 2025 01:50:33 μμ EEST
=====================================================

=====================================================
Training lstm model with config: deep
Starting at Τετ 09 Απρ 2025 01:50:33 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type lstm                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --num_layers 3 --attention_units 128
2025-04-09 13:50:34.357030: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:50:34.516007: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:50:35.103817: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:50:35.103912: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:50:35.103921: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:50:37.821771: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:50:38.493637: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:50:38.493662: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:50:38.493800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4995 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building LSTM model with self-attention...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 5, 50)             19200     
                                                                 
 lstm_1 (LSTM)               (None, 5, 50)             20200     
                                                                 
 lstm_2 (LSTM)               (None, 5, 50)             20200     
                                                                 
 self_attention (SelfAttenti  (None, 50)               6656      
 on)                                                             
                                                                 
 dense (Dense)               (None, 25)                1275      
                                                                 
 dense_1 (Dense)             (None, 1)                 26        
                                                                 
=================================================================
Total params: 67,557
Trainable params: 67,557
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 2:49 - loss: 0.3137 2/27 [=>............................] - ETA: 1s - loss: 0.3045   3/27 [==>...........................] - ETA: 1s - loss: 0.2966 4/27 [===>..........................] - ETA: 1s - loss: 0.2904 5/27 [====>.........................] - ETA: 1s - loss: 0.2636 6/27 [=====>........................] - ETA: 1s - loss: 0.2607 7/27 [======>.......................] - ETA: 1s - loss: 0.2508 8/27 [=======>......................] - ETA: 1s - loss: 0.2381 9/27 [=========>....................] - ETA: 1s - loss: 0.228710/27 [==========>...................] - ETA: 1s - loss: 0.220611/27 [===========>..................] - ETA: 1s - loss: 0.209712/27 [============>.................] - ETA: 1s - loss: 0.197413/27 [=============>................] - ETA: 1s - loss: 0.186414/27 [==============>...............] - ETA: 0s - loss: 0.183215/27 [===============>..............] - ETA: 0s - loss: 0.178216/27 [================>.............] - ETA: 0s - loss: 0.172417/27 [=================>............] - ETA: 0s - loss: 0.164718/27 [===================>..........] - ETA: 0s - loss: 0.157019/27 [====================>.........] - ETA: 0s - loss: 0.149920/27 [=====================>........] - ETA: 0s - loss: 0.144721/27 [======================>.......] - ETA: 0s - loss: 0.139422/27 [=======================>......] - ETA: 0s - loss: 0.136023/27 [========================>.....] - ETA: 0s - loss: 0.131924/27 [=========================>....] - ETA: 0s - loss: 0.129025/27 [==========================>...] - ETA: 0s - loss: 0.126426/27 [===========================>..] - ETA: 0s - loss: 0.122827/27 [==============================] - ETA: 0s - loss: 0.122327/27 [==============================] - 9s 109ms/step - loss: 0.1223 - val_loss: 0.0326 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0541 2/27 [=>............................] - ETA: 1s - loss: 0.0452 3/27 [==>...........................] - ETA: 1s - loss: 0.0442 4/27 [===>..........................] - ETA: 1s - loss: 0.0391 5/27 [====>.........................] - ETA: 1s - loss: 0.0422 6/27 [=====>........................] - ETA: 1s - loss: 0.0402 7/27 [======>.......................] - ETA: 1s - loss: 0.0402 8/27 [=======>......................] - ETA: 1s - loss: 0.0405 9/27 [=========>....................] - ETA: 1s - loss: 0.044510/27 [==========>...................] - ETA: 1s - loss: 0.041711/27 [===========>..................] - ETA: 1s - loss: 0.041712/27 [============>.................] - ETA: 1s - loss: 0.042013/27 [=============>................] - ETA: 1s - loss: 0.040214/27 [==============>...............] - ETA: 0s - loss: 0.038615/27 [===============>..............] - ETA: 0s - loss: 0.038816/27 [================>.............] - ETA: 0s - loss: 0.038717/27 [=================>............] - ETA: 0s - loss: 0.038118/27 [===================>..........] - ETA: 0s - loss: 0.037619/27 [====================>.........] - ETA: 0s - loss: 0.037820/27 [=====================>........] - ETA: 0s - loss: 0.038021/27 [======================>.......] - ETA: 0s - loss: 0.037122/27 [=======================>......] - ETA: 0s - loss: 0.037023/27 [========================>.....] - ETA: 0s - loss: 0.037124/27 [=========================>....] - ETA: 0s - loss: 0.037725/27 [==========================>...] - ETA: 0s - loss: 0.037526/27 [===========================>..] - ETA: 0s - loss: 0.037027/27 [==============================] - ETA: 0s - loss: 0.037027/27 [==============================] - 2s 79ms/step - loss: 0.0370 - val_loss: 0.0017 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 2s - loss: 0.0481 2/27 [=>............................] - ETA: 1s - loss: 0.0376 3/27 [==>...........................] - ETA: 1s - loss: 0.0440 4/27 [===>..........................] - ETA: 1s - loss: 0.0442 5/27 [====>.........................] - ETA: 1s - loss: 0.0411 6/27 [=====>........................] - ETA: 1s - loss: 0.0375 7/27 [======>.......................] - ETA: 1s - loss: 0.0370 8/27 [=======>......................] - ETA: 1s - loss: 0.0388 9/27 [=========>....................] - ETA: 1s - loss: 0.036410/27 [==========>...................] - ETA: 1s - loss: 0.035911/27 [===========>..................] - ETA: 1s - loss: 0.035112/27 [============>.................] - ETA: 1s - loss: 0.035413/27 [=============>................] - ETA: 1s - loss: 0.034114/27 [==============>...............] - ETA: 1s - loss: 0.032715/27 [===============>..............] - ETA: 0s - loss: 0.033716/27 [================>.............] - ETA: 0s - loss: 0.032917/27 [=================>............] - ETA: 0s - loss: 0.033218/27 [===================>..........] - ETA: 0s - loss: 0.032819/27 [====================>.........] - ETA: 0s - loss: 0.033320/27 [=====================>........] - ETA: 0s - loss: 0.033421/27 [======================>.......] - ETA: 0s - loss: 0.033922/27 [=======================>......] - ETA: 0s - loss: 0.033623/27 [========================>.....] - ETA: 0s - loss: 0.033624/27 [=========================>....] - ETA: 0s - loss: 0.033625/27 [==========================>...] - ETA: 0s - loss: 0.034026/27 [===========================>..] - ETA: 0s - loss: 0.034627/27 [==============================] - ETA: 0s - loss: 0.034727/27 [==============================] - 2s 80ms/step - loss: 0.0347 - val_loss: 0.0013 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 2s - loss: 0.0326 2/27 [=>............................] - ETA: 1s - loss: 0.0364 3/27 [==>...........................] - ETA: 1s - loss: 0.0302 4/27 [===>..........................] - ETA: 1s - loss: 0.0319 5/27 [====>.........................] - ETA: 1s - loss: 0.0313 6/27 [=====>........................] - ETA: 1s - loss: 0.0324 7/27 [======>.......................] - ETA: 1s - loss: 0.0314 8/27 [=======>......................] - ETA: 1s - loss: 0.0310 9/27 [=========>....................] - ETA: 1s - loss: 0.031310/27 [==========>...................] - ETA: 1s - loss: 0.031311/27 [===========>..................] - ETA: 1s - loss: 0.033312/27 [============>.................] - ETA: 1s - loss: 0.034413/27 [=============>................] - ETA: 1s - loss: 0.034514/27 [==============>...............] - ETA: 0s - loss: 0.034715/27 [===============>..............] - ETA: 0s - loss: 0.034416/27 [================>.............] - ETA: 0s - loss: 0.034017/27 [=================>............] - ETA: 0s - loss: 0.033218/27 [===================>..........] - ETA: 0s - loss: 0.032519/27 [====================>.........] - ETA: 0s - loss: 0.033220/27 [=====================>........] - ETA: 0s - loss: 0.033221/27 [======================>.......] - ETA: 0s - loss: 0.034922/27 [=======================>......] - ETA: 0s - loss: 0.035023/27 [========================>.....] - ETA: 0s - loss: 0.036624/27 [=========================>....] - ETA: 0s - loss: 0.035725/27 [==========================>...] - ETA: 0s - loss: 0.036926/27 [===========================>..] - ETA: 0s - loss: 0.036927/27 [==============================] - ETA: 0s - loss: 0.037227/27 [==============================] - 2s 80ms/step - loss: 0.0372 - val_loss: 0.0030 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 2s - loss: 0.0404 2/27 [=>............................] - ETA: 1s - loss: 0.0397 3/27 [==>...........................] - ETA: 1s - loss: 0.0433 4/27 [===>..........................] - ETA: 1s - loss: 0.0397 5/27 [====>.........................] - ETA: 1s - loss: 0.0393 6/27 [=====>........................] - ETA: 1s - loss: 0.0392 7/27 [======>.......................] - ETA: 1s - loss: 0.0385 8/27 [=======>......................] - ETA: 1s - loss: 0.0386 9/27 [=========>....................] - ETA: 1s - loss: 0.038310/27 [==========>...................] - ETA: 1s - loss: 0.037311/27 [===========>..................] - ETA: 1s - loss: 0.037212/27 [============>.................] - ETA: 1s - loss: 0.037213/27 [=============>................] - ETA: 1s - loss: 0.039814/27 [==============>...............] - ETA: 0s - loss: 0.039415/27 [===============>..............] - ETA: 0s - loss: 0.037416/27 [================>.............] - ETA: 0s - loss: 0.037617/27 [=================>............] - ETA: 0s - loss: 0.036918/27 [===================>..........] - ETA: 0s - loss: 0.038319/27 [====================>.........] - ETA: 0s - loss: 0.038120/27 [=====================>........] - ETA: 0s - loss: 0.037721/27 [======================>.......] - ETA: 0s - loss: 0.037822/27 [=======================>......] - ETA: 0s - loss: 0.037123/27 [========================>.....] - ETA: 0s - loss: 0.036924/27 [=========================>....] - ETA: 0s - loss: 0.037225/27 [==========================>...] - ETA: 0s - loss: 0.036826/27 [===========================>..] - ETA: 0s - loss: 0.037227/27 [==============================] - ETA: 0s - loss: 0.037127/27 [==============================] - 2s 79ms/step - loss: 0.0371 - val_loss: 0.0085 - lr: 0.0010
Epoch 6/20
 1/27 [>.............................] - ETA: 2s - loss: 0.0390 2/27 [=>............................] - ETA: 1s - loss: 0.0369 3/27 [==>...........................] - ETA: 1s - loss: 0.0373 4/27 [===>..........................] - ETA: 1s - loss: 0.0393 5/27 [====>.........................] - ETA: 1s - loss: 0.0386 6/27 [=====>........................] - ETA: 1s - loss: 0.0374 7/27 [======>.......................] - ETA: 1s - loss: 0.0393 8/27 [=======>......................] - ETA: 1s - loss: 0.0386 9/27 [=========>....................] - ETA: 1s - loss: 0.037210/27 [==========>...................] - ETA: 1s - loss: 0.034611/27 [===========>..................] - ETA: 1s - loss: 0.033912/27 [============>.................] - ETA: 1s - loss: 0.034013/27 [=============>................] - ETA: 1s - loss: 0.033714/27 [==============>...............] - ETA: 0s - loss: 0.035315/27 [===============>..............] - ETA: 0s - loss: 0.035516/27 [================>.............] - ETA: 0s - loss: 0.034717/27 [=================>............] - ETA: 0s - loss: 0.034818/27 [===================>..........] - ETA: 0s - loss: 0.034719/27 [====================>.........] - ETA: 0s - loss: 0.033720/27 [=====================>........] - ETA: 0s - loss: 0.034521/27 [======================>.......] - ETA: 0s - loss: 0.034222/27 [=======================>......] - ETA: 0s - loss: 0.034023/27 [========================>.....] - ETA: 0s - loss: 0.034424/27 [=========================>....] - ETA: 0s - loss: 0.035425/27 [==========================>...] - ETA: 0s - loss: 0.035226/27 [===========================>..] - ETA: 0s - loss: 0.035527/27 [==============================] - ETA: 0s - loss: 0.035527/27 [==============================] - 2s 80ms/step - loss: 0.0355 - val_loss: 0.0035 - lr: 5.0000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.00215/5 [==============================] - ETA: 0s - loss: 0.00405/5 [==============================] - 0s 14ms/step - loss: 0.0040
Test Loss: 0.004016981925815344
Saved model as forecasting_models_v5/model_lstm_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for LSTM model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 675ms/step
Predicted QoE for the next time step: 88.1499688842976
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/lstm_deep.h5
Completed at Τετ 09 Απρ 2025 01:51:02 μμ EEST
=====================================================

=====================================================
Training lstm model with config: wide
Starting at Τετ 09 Απρ 2025 01:51:02 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type lstm                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --hidden_units 100 --attention_units 128
2025-04-09 13:51:03.342014: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:51:03.499078: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:51:04.158219: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:51:04.158341: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:51:04.158355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:51:07.020843: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:51:07.725835: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:51:07.725861: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:51:07.726004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4975 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building LSTM model with self-attention...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 5, 100)            58400     
                                                                 
 lstm_1 (LSTM)               (None, 5, 100)            80400     
                                                                 
 self_attention (SelfAttenti  (None, 100)              13056     
 on)                                                             
                                                                 
 dense (Dense)               (None, 25)                2525      
                                                                 
 dense_1 (Dense)             (None, 1)                 26        
                                                                 
=================================================================
Total params: 154,407
Trainable params: 154,407
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 2:22 - loss: 0.3106 2/27 [=>............................] - ETA: 1s - loss: 0.2835   3/27 [==>...........................] - ETA: 1s - loss: 0.2531 4/27 [===>..........................] - ETA: 1s - loss: 0.2192 6/27 [=====>........................] - ETA: 1s - loss: 0.1926 8/27 [=======>......................] - ETA: 0s - loss: 0.159710/27 [==========>...................] - ETA: 0s - loss: 0.148511/27 [===========>..................] - ETA: 0s - loss: 0.141113/27 [=============>................] - ETA: 0s - loss: 0.129014/27 [==============>...............] - ETA: 0s - loss: 0.122616/27 [================>.............] - ETA: 0s - loss: 0.115718/27 [===================>..........] - ETA: 0s - loss: 0.106820/27 [=====================>........] - ETA: 0s - loss: 0.101121/27 [======================>.......] - ETA: 0s - loss: 0.098122/27 [=======================>......] - ETA: 0s - loss: 0.095923/27 [========================>.....] - ETA: 0s - loss: 0.093124/27 [=========================>....] - ETA: 0s - loss: 0.091925/27 [==========================>...] - ETA: 0s - loss: 0.091026/27 [===========================>..] - ETA: 0s - loss: 0.089427/27 [==============================] - ETA: 0s - loss: 0.089127/27 [==============================] - 8s 83ms/step - loss: 0.0891 - val_loss: 0.0107 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0666 2/27 [=>............................] - ETA: 1s - loss: 0.0410 4/27 [===>..........................] - ETA: 1s - loss: 0.0412 5/27 [====>.........................] - ETA: 1s - loss: 0.0380 7/27 [======>.......................] - ETA: 1s - loss: 0.0353 8/27 [=======>......................] - ETA: 0s - loss: 0.039710/27 [==========>...................] - ETA: 0s - loss: 0.040811/27 [===========>..................] - ETA: 0s - loss: 0.039813/27 [=============>................] - ETA: 0s - loss: 0.039414/27 [==============>...............] - ETA: 0s - loss: 0.040915/27 [===============>..............] - ETA: 0s - loss: 0.040016/27 [================>.............] - ETA: 0s - loss: 0.042017/27 [=================>............] - ETA: 0s - loss: 0.041718/27 [===================>..........] - ETA: 0s - loss: 0.041519/27 [====================>.........] - ETA: 0s - loss: 0.040820/27 [=====================>........] - ETA: 0s - loss: 0.039622/27 [=======================>......] - ETA: 0s - loss: 0.037723/27 [========================>.....] - ETA: 0s - loss: 0.037224/27 [=========================>....] - ETA: 0s - loss: 0.036326/27 [===========================>..] - ETA: 0s - loss: 0.037827/27 [==============================] - 2s 58ms/step - loss: 0.0377 - val_loss: 0.0025 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0263 3/27 [==>...........................] - ETA: 1s - loss: 0.0411 4/27 [===>..........................] - ETA: 1s - loss: 0.0397 5/27 [====>.........................] - ETA: 1s - loss: 0.0396 6/27 [=====>........................] - ETA: 1s - loss: 0.0382 7/27 [======>.......................] - ETA: 1s - loss: 0.0367 8/27 [=======>......................] - ETA: 1s - loss: 0.038510/27 [==========>...................] - ETA: 0s - loss: 0.039312/27 [============>.................] - ETA: 0s - loss: 0.036914/27 [==============>...............] - ETA: 0s - loss: 0.037515/27 [===============>..............] - ETA: 0s - loss: 0.037717/27 [=================>............] - ETA: 0s - loss: 0.037819/27 [====================>.........] - ETA: 0s - loss: 0.038021/27 [======================>.......] - ETA: 0s - loss: 0.038023/27 [========================>.....] - ETA: 0s - loss: 0.036925/27 [==========================>...] - ETA: 0s - loss: 0.037427/27 [==============================] - ETA: 0s - loss: 0.037527/27 [==============================] - 1s 53ms/step - loss: 0.0375 - val_loss: 0.0092 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0454 2/27 [=>............................] - ETA: 1s - loss: 0.0375 4/27 [===>..........................] - ETA: 1s - loss: 0.0389 6/27 [=====>........................] - ETA: 0s - loss: 0.0416 7/27 [======>.......................] - ETA: 0s - loss: 0.0407 8/27 [=======>......................] - ETA: 0s - loss: 0.039510/27 [==========>...................] - ETA: 0s - loss: 0.040512/27 [============>.................] - ETA: 0s - loss: 0.038914/27 [==============>...............] - ETA: 0s - loss: 0.036815/27 [===============>..............] - ETA: 0s - loss: 0.039217/27 [=================>............] - ETA: 0s - loss: 0.038819/27 [====================>.........] - ETA: 0s - loss: 0.038221/27 [======================>.......] - ETA: 0s - loss: 0.037822/27 [=======================>......] - ETA: 0s - loss: 0.036723/27 [========================>.....] - ETA: 0s - loss: 0.036824/27 [=========================>....] - ETA: 0s - loss: 0.036425/27 [==========================>...] - ETA: 0s - loss: 0.035526/27 [===========================>..] - ETA: 0s - loss: 0.035127/27 [==============================] - 1s 53ms/step - loss: 0.0350 - val_loss: 0.0026 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0439 3/27 [==>...........................] - ETA: 1s - loss: 0.0308 5/27 [====>.........................] - ETA: 1s - loss: 0.0294 7/27 [======>.......................] - ETA: 0s - loss: 0.0335 8/27 [=======>......................] - ETA: 0s - loss: 0.036810/27 [==========>...................] - ETA: 0s - loss: 0.036212/27 [============>.................] - ETA: 0s - loss: 0.034114/27 [==============>...............] - ETA: 0s - loss: 0.032916/27 [================>.............] - ETA: 0s - loss: 0.034017/27 [=================>............] - ETA: 0s - loss: 0.034919/27 [====================>.........] - ETA: 0s - loss: 0.035121/27 [======================>.......] - ETA: 0s - loss: 0.034123/27 [========================>.....] - ETA: 0s - loss: 0.035324/27 [=========================>....] - ETA: 0s - loss: 0.034726/27 [===========================>..] - ETA: 0s - loss: 0.033827/27 [==============================] - ETA: 0s - loss: 0.033927/27 [==============================] - 1s 54ms/step - loss: 0.0339 - val_loss: 0.0036 - lr: 5.0000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.00385/5 [==============================] - 0s 9ms/step - loss: 0.0068
Test Loss: 0.006766232196241617
Saved model as forecasting_models_v5/model_lstm_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for LSTM model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 510ms/step
Predicted QoE for the next time step: 91.24345182045937
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/lstm_wide.h5
Completed at Τετ 09 Απρ 2025 01:51:25 μμ EEST
=====================================================

=====================================================
Training lstm model with config: bidirectional
Starting at Τετ 09 Απρ 2025 01:51:25 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type lstm                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --bidirectional --attention_units 128
2025-04-09 13:51:25.708913: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:51:25.867599: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:51:26.479587: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:51:26.479688: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:51:26.479706: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:51:29.222970: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:51:29.946842: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:51:29.946868: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:51:29.947001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4961 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building LSTM model with self-attention...
Traceback (most recent call last):
  File "timeseries_forecasting_models_v5.py", line 889, in <module>
    main()
  File "timeseries_forecasting_models_v5.py", line 720, in main
    model.summary()
  File "/home/dimitris/.local/lib/python3.8/site-packages/keras/engine/training.py", line 3214, in summary
    raise ValueError(
ValueError: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.
Warning: Original model file not found at /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/model_lstm_with_attention.h5
Directory contents:
total 4812
drwxrwxr-x  2 dimitris dimitris    4096 Απρ   9 13:51 .
drwxrwxr-x 15 dimitris dimitris    4096 Απρ   9 13:43 ..
-rw-rw-r--  1 dimitris dimitris  233792 Απρ   9 13:49 dnn_basic.h5
-rw-rw-r--  1 dimitris dimitris  519208 Απρ   9 13:49 dnn_deep.h5
-rw-rw-r--  1 dimitris dimitris  233792 Απρ   9 13:49 dnn_with_elu.h5
-rw-rw-r--  1 dimitris dimitris  233792 Απρ   9 13:50 dnn_with_high_dropout.h5
-rw-rw-r--  1 dimitris dimitris   22064 Απρ   9 13:48 linear_basic.h5
-rw-rw-r--  1 dimitris dimitris   22064 Απρ   9 13:49 linear_with_elastic_net.h5
-rw-rw-r--  1 dimitris dimitris   22064 Απρ   9 13:49 linear_with_l1_reg.h5
-rw-rw-r--  1 dimitris dimitris   22064 Απρ   9 13:49 linear_with_l2_reg.h5
-rw-rw-r--  1 dimitris dimitris  628760 Απρ   9 13:50 lstm_basic.h5
-rw-rw-r--  1 dimitris dimitris  881952 Απρ   9 13:50 lstm_deep.h5
-rw-rw-r--  1 dimitris dimitris 1914264 Απρ   9 13:51 lstm_wide.h5
-rw-rw-r--  1 dimitris dimitris    3463 Απρ   9 13:51 scaler.save
-rw-rw-r--  1 dimitris dimitris  145059 Απρ   9 13:51 training_log.txt
Completed at Τετ 09 Απρ 2025 01:51:32 μμ EEST
=====================================================

=====================================================
Training lstm model with config: with_stats
Starting at Τετ 09 Απρ 2025 01:51:32 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type lstm                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --attention_units 128
2025-04-09 13:51:32.991407: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:51:33.141136: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:51:33.729166: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:51:33.729246: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:51:33.729267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:51:36.371745: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:51:37.062005: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:51:37.062035: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:51:37.062200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4962 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building LSTM model with self-attention...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 5, 50)             19200     
                                                                 
 lstm_1 (LSTM)               (None, 5, 50)             20200     
                                                                 
 self_attention (SelfAttenti  (None, 50)               6656      
 on)                                                             
                                                                 
 dense (Dense)               (None, 25)                1275      
                                                                 
 dense_1 (Dense)             (None, 1)                 26        
                                                                 
=================================================================
Total params: 47,357
Trainable params: 47,357
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 1:55 - loss: 0.3043 3/27 [==>...........................] - ETA: 1s - loss: 0.2757   4/27 [===>..........................] - ETA: 1s - loss: 0.2564 6/27 [=====>........................] - ETA: 1s - loss: 0.2501 8/27 [=======>......................] - ETA: 0s - loss: 0.229310/27 [==========>...................] - ETA: 0s - loss: 0.214611/27 [===========>..................] - ETA: 0s - loss: 0.206013/27 [=============>................] - ETA: 0s - loss: 0.190214/27 [==============>...............] - ETA: 0s - loss: 0.184315/27 [===============>..............] - ETA: 0s - loss: 0.178216/27 [================>.............] - ETA: 0s - loss: 0.171918/27 [===================>..........] - ETA: 0s - loss: 0.163619/27 [====================>.........] - ETA: 0s - loss: 0.157921/27 [======================>.......] - ETA: 0s - loss: 0.148222/27 [=======================>......] - ETA: 0s - loss: 0.143123/27 [========================>.....] - ETA: 0s - loss: 0.138025/27 [==========================>...] - ETA: 0s - loss: 0.130427/27 [==============================] - ETA: 0s - loss: 0.126927/27 [==============================] - 6s 76ms/step - loss: 0.1269 - val_loss: 0.0274 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0242 3/27 [==>...........................] - ETA: 1s - loss: 0.0373 5/27 [====>.........................] - ETA: 1s - loss: 0.0371 7/27 [======>.......................] - ETA: 0s - loss: 0.0334 9/27 [=========>....................] - ETA: 0s - loss: 0.035911/27 [===========>..................] - ETA: 0s - loss: 0.039113/27 [=============>................] - ETA: 0s - loss: 0.040114/27 [==============>...............] - ETA: 0s - loss: 0.039316/27 [================>.............] - ETA: 0s - loss: 0.038718/27 [===================>..........] - ETA: 0s - loss: 0.039820/27 [=====================>........] - ETA: 0s - loss: 0.040122/27 [=======================>......] - ETA: 0s - loss: 0.039024/27 [=========================>....] - ETA: 0s - loss: 0.037426/27 [===========================>..] - ETA: 0s - loss: 0.037127/27 [==============================] - 1s 50ms/step - loss: 0.0373 - val_loss: 0.0021 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0364 2/27 [=>............................] - ETA: 1s - loss: 0.0312 3/27 [==>...........................] - ETA: 1s - loss: 0.0427 4/27 [===>..........................] - ETA: 1s - loss: 0.0408 6/27 [=====>........................] - ETA: 1s - loss: 0.0380 8/27 [=======>......................] - ETA: 0s - loss: 0.0356 9/27 [=========>....................] - ETA: 0s - loss: 0.035010/27 [==========>...................] - ETA: 0s - loss: 0.035411/27 [===========>..................] - ETA: 0s - loss: 0.034312/27 [============>.................] - ETA: 0s - loss: 0.036013/27 [=============>................] - ETA: 0s - loss: 0.036015/27 [===============>..............] - ETA: 0s - loss: 0.036717/27 [=================>............] - ETA: 0s - loss: 0.037919/27 [====================>.........] - ETA: 0s - loss: 0.037320/27 [=====================>........] - ETA: 0s - loss: 0.038921/27 [======================>.......] - ETA: 0s - loss: 0.038622/27 [=======================>......] - ETA: 0s - loss: 0.038523/27 [========================>.....] - ETA: 0s - loss: 0.038625/27 [==========================>...] - ETA: 0s - loss: 0.037126/27 [===========================>..] - ETA: 0s - loss: 0.036427/27 [==============================] - ETA: 0s - loss: 0.036927/27 [==============================] - 1s 56ms/step - loss: 0.0369 - val_loss: 0.0013 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0377 2/27 [=>............................] - ETA: 1s - loss: 0.0381 4/27 [===>..........................] - ETA: 1s - loss: 0.0392 5/27 [====>.........................] - ETA: 1s - loss: 0.0398 6/27 [=====>........................] - ETA: 1s - loss: 0.0418 7/27 [======>.......................] - ETA: 1s - loss: 0.0421 8/27 [=======>......................] - ETA: 0s - loss: 0.039110/27 [==========>...................] - ETA: 0s - loss: 0.036811/27 [===========>..................] - ETA: 0s - loss: 0.037013/27 [=============>................] - ETA: 0s - loss: 0.038714/27 [==============>...............] - ETA: 0s - loss: 0.038116/27 [================>.............] - ETA: 0s - loss: 0.036918/27 [===================>..........] - ETA: 0s - loss: 0.035819/27 [====================>.........] - ETA: 0s - loss: 0.036020/27 [=====================>........] - ETA: 0s - loss: 0.036121/27 [======================>.......] - ETA: 0s - loss: 0.035723/27 [========================>.....] - ETA: 0s - loss: 0.035724/27 [=========================>....] - ETA: 0s - loss: 0.035425/27 [==========================>...] - ETA: 0s - loss: 0.035326/27 [===========================>..] - ETA: 0s - loss: 0.035727/27 [==============================] - ETA: 0s - loss: 0.035627/27 [==============================] - 2s 56ms/step - loss: 0.0356 - val_loss: 0.0024 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0436 3/27 [==>...........................] - ETA: 1s - loss: 0.0258 5/27 [====>.........................] - ETA: 1s - loss: 0.0388 6/27 [=====>........................] - ETA: 0s - loss: 0.0377 7/27 [======>.......................] - ETA: 0s - loss: 0.0374 8/27 [=======>......................] - ETA: 0s - loss: 0.0411 9/27 [=========>....................] - ETA: 0s - loss: 0.038311/27 [===========>..................] - ETA: 0s - loss: 0.037912/27 [============>.................] - ETA: 0s - loss: 0.037513/27 [=============>................] - ETA: 0s - loss: 0.036515/27 [===============>..............] - ETA: 0s - loss: 0.037117/27 [=================>............] - ETA: 0s - loss: 0.038218/27 [===================>..........] - ETA: 0s - loss: 0.037619/27 [====================>.........] - ETA: 0s - loss: 0.038021/27 [======================>.......] - ETA: 0s - loss: 0.037622/27 [=======================>......] - ETA: 0s - loss: 0.038423/27 [========================>.....] - ETA: 0s - loss: 0.037424/27 [=========================>....] - ETA: 0s - loss: 0.036525/27 [==========================>...] - ETA: 0s - loss: 0.036126/27 [===========================>..] - ETA: 0s - loss: 0.035827/27 [==============================] - ETA: 0s - loss: 0.035727/27 [==============================] - 1s 54ms/step - loss: 0.0357 - val_loss: 7.2040e-04 - lr: 0.0010
Epoch 6/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0475 2/27 [=>............................] - ETA: 1s - loss: 0.0507 3/27 [==>...........................] - ETA: 1s - loss: 0.0436 4/27 [===>..........................] - ETA: 1s - loss: 0.0485 5/27 [====>.........................] - ETA: 1s - loss: 0.0437 6/27 [=====>........................] - ETA: 1s - loss: 0.0395 7/27 [======>.......................] - ETA: 1s - loss: 0.0400 9/27 [=========>....................] - ETA: 0s - loss: 0.039311/27 [===========>..................] - ETA: 0s - loss: 0.038312/27 [============>.................] - ETA: 0s - loss: 0.036513/27 [=============>................] - ETA: 0s - loss: 0.035214/27 [==============>...............] - ETA: 0s - loss: 0.034315/27 [===============>..............] - ETA: 0s - loss: 0.035117/27 [=================>............] - ETA: 0s - loss: 0.036018/27 [===================>..........] - ETA: 0s - loss: 0.036220/27 [=====================>........] - ETA: 0s - loss: 0.035721/27 [======================>.......] - ETA: 0s - loss: 0.035222/27 [=======================>......] - ETA: 0s - loss: 0.034823/27 [========================>.....] - ETA: 0s - loss: 0.035724/27 [=========================>....] - ETA: 0s - loss: 0.035625/27 [==========================>...] - ETA: 0s - loss: 0.034626/27 [===========================>..] - ETA: 0s - loss: 0.034827/27 [==============================] - 1s 56ms/step - loss: 0.0347 - val_loss: 0.0011 - lr: 0.0010
Epoch 7/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0259 2/27 [=>............................] - ETA: 1s - loss: 0.0372 4/27 [===>..........................] - ETA: 1s - loss: 0.0342 6/27 [=====>........................] - ETA: 1s - loss: 0.0305 7/27 [======>.......................] - ETA: 0s - loss: 0.0337 9/27 [=========>....................] - ETA: 0s - loss: 0.034011/27 [===========>..................] - ETA: 0s - loss: 0.033813/27 [=============>................] - ETA: 0s - loss: 0.033815/27 [===============>..............] - ETA: 0s - loss: 0.031917/27 [=================>............] - ETA: 0s - loss: 0.031518/27 [===================>..........] - ETA: 0s - loss: 0.031120/27 [=====================>........] - ETA: 0s - loss: 0.031522/27 [=======================>......] - ETA: 0s - loss: 0.032623/27 [========================>.....] - ETA: 0s - loss: 0.033124/27 [=========================>....] - ETA: 0s - loss: 0.033025/27 [==========================>...] - ETA: 0s - loss: 0.034726/27 [===========================>..] - ETA: 0s - loss: 0.034127/27 [==============================] - 1s 54ms/step - loss: 0.0340 - val_loss: 0.0082 - lr: 0.0010
Epoch 8/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0220 2/27 [=>............................] - ETA: 1s - loss: 0.0255 3/27 [==>...........................] - ETA: 1s - loss: 0.0285 5/27 [====>.........................] - ETA: 1s - loss: 0.0287 7/27 [======>.......................] - ETA: 1s - loss: 0.0283 8/27 [=======>......................] - ETA: 0s - loss: 0.027510/27 [==========>...................] - ETA: 0s - loss: 0.027312/27 [============>.................] - ETA: 0s - loss: 0.034513/27 [=============>................] - ETA: 0s - loss: 0.033215/27 [===============>..............] - ETA: 0s - loss: 0.033916/27 [================>.............] - ETA: 0s - loss: 0.035118/27 [===================>..........] - ETA: 0s - loss: 0.035319/27 [====================>.........] - ETA: 0s - loss: 0.034421/27 [======================>.......] - ETA: 0s - loss: 0.034323/27 [========================>.....] - ETA: 0s - loss: 0.034725/27 [==========================>...] - ETA: 0s - loss: 0.034127/27 [==============================] - ETA: 0s - loss: 0.034027/27 [==============================] - 1s 55ms/step - loss: 0.0340 - val_loss: 0.0021 - lr: 5.0000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.00225/5 [==============================] - 0s 10ms/step - loss: 0.0073
Test Loss: 0.007314280606806278
Saved model as forecasting_models_v5/model_lstm_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for LSTM model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 505ms/step
Predicted QoE for the next time step: 85.04203737104774
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/lstm_with_stats.h5
Completed at Τετ 09 Απρ 2025 01:51:57 μμ EEST
=====================================================

=====================================================
Training gru model with config: basic
Starting at Τετ 09 Απρ 2025 01:51:57 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type gru                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --attention_units 128
2025-04-09 13:51:58.132286: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:51:58.295401: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:51:58.906088: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:51:58.906207: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:51:58.906220: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:52:01.560255: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:52:02.251658: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:52:02.251682: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:52:02.251815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4956 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building GRU model with self-attention...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 gru (GRU)                   (None, 5, 50)             14550     
                                                                 
 gru_1 (GRU)                 (None, 5, 50)             15300     
                                                                 
 self_attention (SelfAttenti  (None, 50)               6656      
 on)                                                             
                                                                 
 dense (Dense)               (None, 25)                1275      
                                                                 
 dense_1 (Dense)             (None, 1)                 26        
                                                                 
=================================================================
Total params: 37,807
Trainable params: 37,807
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 1:55 - loss: 0.2399 3/27 [==>...........................] - ETA: 1s - loss: 0.2107   5/27 [====>.........................] - ETA: 0s - loss: 0.1613 7/27 [======>.......................] - ETA: 0s - loss: 0.1455 9/27 [=========>....................] - ETA: 0s - loss: 0.125711/27 [===========>..................] - ETA: 0s - loss: 0.117813/27 [=============>................] - ETA: 0s - loss: 0.109915/27 [===============>..............] - ETA: 0s - loss: 0.102517/27 [=================>............] - ETA: 0s - loss: 0.094819/27 [====================>.........] - ETA: 0s - loss: 0.090321/27 [======================>.......] - ETA: 0s - loss: 0.084023/27 [========================>.....] - ETA: 0s - loss: 0.080025/27 [==========================>...] - ETA: 0s - loss: 0.077227/27 [==============================] - ETA: 0s - loss: 0.075427/27 [==============================] - 6s 73ms/step - loss: 0.0754 - val_loss: 2.9723e-04 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0465 2/27 [=>............................] - ETA: 1s - loss: 0.0468 4/27 [===>..........................] - ETA: 1s - loss: 0.0404 6/27 [=====>........................] - ETA: 1s - loss: 0.0388 8/27 [=======>......................] - ETA: 0s - loss: 0.040910/27 [==========>...................] - ETA: 0s - loss: 0.039812/27 [============>.................] - ETA: 0s - loss: 0.040214/27 [==============>...............] - ETA: 0s - loss: 0.038515/27 [===============>..............] - ETA: 0s - loss: 0.037517/27 [=================>............] - ETA: 0s - loss: 0.038519/27 [====================>.........] - ETA: 0s - loss: 0.038421/27 [======================>.......] - ETA: 0s - loss: 0.037023/27 [========================>.....] - ETA: 0s - loss: 0.037025/27 [==========================>...] - ETA: 0s - loss: 0.037626/27 [===========================>..] - ETA: 0s - loss: 0.037727/27 [==============================] - 1s 50ms/step - loss: 0.0376 - val_loss: 1.7201e-04 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0345 3/27 [==>...........................] - ETA: 1s - loss: 0.0370 5/27 [====>.........................] - ETA: 1s - loss: 0.0344 7/27 [======>.......................] - ETA: 0s - loss: 0.0316 9/27 [=========>....................] - ETA: 0s - loss: 0.032111/27 [===========>..................] - ETA: 0s - loss: 0.036013/27 [=============>................] - ETA: 0s - loss: 0.035114/27 [==============>...............] - ETA: 0s - loss: 0.035616/27 [================>.............] - ETA: 0s - loss: 0.035418/27 [===================>..........] - ETA: 0s - loss: 0.035520/27 [=====================>........] - ETA: 0s - loss: 0.035822/27 [=======================>......] - ETA: 0s - loss: 0.036824/27 [=========================>....] - ETA: 0s - loss: 0.035826/27 [===========================>..] - ETA: 0s - loss: 0.036827/27 [==============================] - 1s 49ms/step - loss: 0.0367 - val_loss: 0.0013 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0318 3/27 [==>...........................] - ETA: 1s - loss: 0.0277 5/27 [====>.........................] - ETA: 1s - loss: 0.0367 7/27 [======>.......................] - ETA: 0s - loss: 0.0354 9/27 [=========>....................] - ETA: 0s - loss: 0.033411/27 [===========>..................] - ETA: 0s - loss: 0.033713/27 [=============>................] - ETA: 0s - loss: 0.034715/27 [===============>..............] - ETA: 0s - loss: 0.033917/27 [=================>............] - ETA: 0s - loss: 0.034419/27 [====================>.........] - ETA: 0s - loss: 0.034921/27 [======================>.......] - ETA: 0s - loss: 0.035323/27 [========================>.....] - ETA: 0s - loss: 0.035025/27 [==========================>...] - ETA: 0s - loss: 0.036627/27 [==============================] - ETA: 0s - loss: 0.036327/27 [==============================] - 1s 51ms/step - loss: 0.0363 - val_loss: 1.0849e-04 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0351 2/27 [=>............................] - ETA: 1s - loss: 0.0416 3/27 [==>...........................] - ETA: 1s - loss: 0.0348 5/27 [====>.........................] - ETA: 1s - loss: 0.0309 7/27 [======>.......................] - ETA: 0s - loss: 0.0341 9/27 [=========>....................] - ETA: 0s - loss: 0.035911/27 [===========>..................] - ETA: 0s - loss: 0.036413/27 [=============>................] - ETA: 0s - loss: 0.036714/27 [==============>...............] - ETA: 0s - loss: 0.035615/27 [===============>..............] - ETA: 0s - loss: 0.034417/27 [=================>............] - ETA: 0s - loss: 0.035219/27 [====================>.........] - ETA: 0s - loss: 0.035120/27 [=====================>........] - ETA: 0s - loss: 0.035922/27 [=======================>......] - ETA: 0s - loss: 0.035323/27 [========================>.....] - ETA: 0s - loss: 0.035224/27 [=========================>....] - ETA: 0s - loss: 0.035626/27 [===========================>..] - ETA: 0s - loss: 0.035127/27 [==============================] - 1s 52ms/step - loss: 0.0349 - val_loss: 8.7492e-04 - lr: 5.0000e-04
Epoch 6/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0325 3/27 [==>...........................] - ETA: 1s - loss: 0.0329 4/27 [===>..........................] - ETA: 1s - loss: 0.0367 6/27 [=====>........................] - ETA: 0s - loss: 0.0391 8/27 [=======>......................] - ETA: 0s - loss: 0.035210/27 [==========>...................] - ETA: 0s - loss: 0.033411/27 [===========>..................] - ETA: 0s - loss: 0.032513/27 [=============>................] - ETA: 0s - loss: 0.032814/27 [==============>...............] - ETA: 0s - loss: 0.033016/27 [================>.............] - ETA: 0s - loss: 0.034518/27 [===================>..........] - ETA: 0s - loss: 0.034220/27 [=====================>........] - ETA: 0s - loss: 0.035521/27 [======================>.......] - ETA: 0s - loss: 0.035122/27 [=======================>......] - ETA: 0s - loss: 0.035323/27 [========================>.....] - ETA: 0s - loss: 0.035125/27 [==========================>...] - ETA: 0s - loss: 0.034626/27 [===========================>..] - ETA: 0s - loss: 0.033827/27 [==============================] - 1s 51ms/step - loss: 0.0338 - val_loss: 1.1341e-04 - lr: 5.0000e-04
Epoch 7/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0322 3/27 [==>...........................] - ETA: 1s - loss: 0.0352 5/27 [====>.........................] - ETA: 1s - loss: 0.0333 7/27 [======>.......................] - ETA: 0s - loss: 0.0357 8/27 [=======>......................] - ETA: 0s - loss: 0.036910/27 [==========>...................] - ETA: 0s - loss: 0.034011/27 [===========>..................] - ETA: 0s - loss: 0.033513/27 [=============>................] - ETA: 0s - loss: 0.032715/27 [===============>..............] - ETA: 0s - loss: 0.032917/27 [=================>............] - ETA: 0s - loss: 0.034619/27 [====================>.........] - ETA: 0s - loss: 0.032921/27 [======================>.......] - ETA: 0s - loss: 0.032823/27 [========================>.....] - ETA: 0s - loss: 0.034125/27 [==========================>...] - ETA: 0s - loss: 0.033927/27 [==============================] - ETA: 0s - loss: 0.034027/27 [==============================] - 1s 50ms/step - loss: 0.0340 - val_loss: 1.0700e-04 - lr: 2.5000e-04
Epoch 8/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0232 3/27 [==>...........................] - ETA: 1s - loss: 0.0268 5/27 [====>.........................] - ETA: 0s - loss: 0.0304 7/27 [======>.......................] - ETA: 0s - loss: 0.0321 9/27 [=========>....................] - ETA: 0s - loss: 0.030911/27 [===========>..................] - ETA: 0s - loss: 0.032812/27 [============>.................] - ETA: 0s - loss: 0.033714/27 [==============>...............] - ETA: 0s - loss: 0.037416/27 [================>.............] - ETA: 0s - loss: 0.035118/27 [===================>..........] - ETA: 0s - loss: 0.036520/27 [=====================>........] - ETA: 0s - loss: 0.035221/27 [======================>.......] - ETA: 0s - loss: 0.034623/27 [========================>.....] - ETA: 0s - loss: 0.034925/27 [==========================>...] - ETA: 0s - loss: 0.035227/27 [==============================] - ETA: 0s - loss: 0.034827/27 [==============================] - 1s 49ms/step - loss: 0.0348 - val_loss: 3.1216e-04 - lr: 2.5000e-04
Epoch 9/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0395 3/27 [==>...........................] - ETA: 1s - loss: 0.0375 5/27 [====>.........................] - ETA: 1s - loss: 0.0385 7/27 [======>.......................] - ETA: 0s - loss: 0.0337 9/27 [=========>....................] - ETA: 0s - loss: 0.029111/27 [===========>..................] - ETA: 0s - loss: 0.029813/27 [=============>................] - ETA: 0s - loss: 0.030915/27 [===============>..............] - ETA: 0s - loss: 0.033517/27 [=================>............] - ETA: 0s - loss: 0.034118/27 [===================>..........] - ETA: 0s - loss: 0.034420/27 [=====================>........] - ETA: 0s - loss: 0.033922/27 [=======================>......] - ETA: 0s - loss: 0.035224/27 [=========================>....] - ETA: 0s - loss: 0.034726/27 [===========================>..] - ETA: 0s - loss: 0.035027/27 [==============================] - 1s 51ms/step - loss: 0.0350 - val_loss: 1.0668e-04 - lr: 1.2500e-04
Epoch 10/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0223 3/27 [==>...........................] - ETA: 1s - loss: 0.0349 4/27 [===>..........................] - ETA: 1s - loss: 0.0403 6/27 [=====>........................] - ETA: 0s - loss: 0.0364 8/27 [=======>......................] - ETA: 0s - loss: 0.033810/27 [==========>...................] - ETA: 0s - loss: 0.032011/27 [===========>..................] - ETA: 0s - loss: 0.031713/27 [=============>................] - ETA: 0s - loss: 0.032314/27 [==============>...............] - ETA: 0s - loss: 0.033216/27 [================>.............] - ETA: 0s - loss: 0.034118/27 [===================>..........] - ETA: 0s - loss: 0.034119/27 [====================>.........] - ETA: 0s - loss: 0.034920/27 [=====================>........] - ETA: 0s - loss: 0.034621/27 [======================>.......] - ETA: 0s - loss: 0.035022/27 [=======================>......] - ETA: 0s - loss: 0.035723/27 [========================>.....] - ETA: 0s - loss: 0.035524/27 [=========================>....] - ETA: 0s - loss: 0.034726/27 [===========================>..] - ETA: 0s - loss: 0.034727/27 [==============================] - 1s 52ms/step - loss: 0.0346 - val_loss: 1.3210e-04 - lr: 1.2500e-04
Epoch 11/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0285 2/27 [=>............................] - ETA: 1s - loss: 0.0357 4/27 [===>..........................] - ETA: 1s - loss: 0.0303 6/27 [=====>........................] - ETA: 1s - loss: 0.0356 8/27 [=======>......................] - ETA: 0s - loss: 0.0330 9/27 [=========>....................] - ETA: 0s - loss: 0.032811/27 [===========>..................] - ETA: 0s - loss: 0.034613/27 [=============>................] - ETA: 0s - loss: 0.033814/27 [==============>...............] - ETA: 0s - loss: 0.034516/27 [================>.............] - ETA: 0s - loss: 0.035017/27 [=================>............] - ETA: 0s - loss: 0.035318/27 [===================>..........] - ETA: 0s - loss: 0.035720/27 [=====================>........] - ETA: 0s - loss: 0.035822/27 [=======================>......] - ETA: 0s - loss: 0.035823/27 [========================>.....] - ETA: 0s - loss: 0.035224/27 [=========================>....] - ETA: 0s - loss: 0.034926/27 [===========================>..] - ETA: 0s - loss: 0.033827/27 [==============================] - 1s 52ms/step - loss: 0.0338 - val_loss: 1.0856e-04 - lr: 6.2500e-05
Epoch 12/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0097 3/27 [==>...........................] - ETA: 1s - loss: 0.0241 5/27 [====>.........................] - ETA: 1s - loss: 0.0312 7/27 [======>.......................] - ETA: 0s - loss: 0.0285 9/27 [=========>....................] - ETA: 0s - loss: 0.029311/27 [===========>..................] - ETA: 0s - loss: 0.029012/27 [============>.................] - ETA: 0s - loss: 0.029514/27 [==============>...............] - ETA: 0s - loss: 0.031416/27 [================>.............] - ETA: 0s - loss: 0.030218/27 [===================>..........] - ETA: 0s - loss: 0.032020/27 [=====================>........] - ETA: 0s - loss: 0.033722/27 [=======================>......] - ETA: 0s - loss: 0.034224/27 [=========================>....] - ETA: 0s - loss: 0.034626/27 [===========================>..] - ETA: 0s - loss: 0.034627/27 [==============================] - 1s 50ms/step - loss: 0.0346 - val_loss: 2.4583e-04 - lr: 6.2500e-05
1/5 [=====>........................] - ETA: 0s - loss: 1.1451e-045/5 [==============================] - 0s 10ms/step - loss: 2.1846e-04
Test Loss: 0.00021845557785127312
Saved model as forecasting_models_v5/model_gru_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for GRU model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 614ms/step
Predicted QoE for the next time step: 104.47293532072543
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/gru_basic.h5
Completed at Τετ 09 Απρ 2025 01:52:27 μμ EEST
=====================================================

=====================================================
Training gru model with config: deep
Starting at Τετ 09 Απρ 2025 01:52:27 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type gru                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --num_layers 3 --attention_units 128
2025-04-09 13:52:28.277921: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:52:28.437672: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:52:29.018101: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:52:29.018181: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:52:29.018202: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:52:31.720683: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:52:32.398227: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:52:32.398250: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:52:32.398441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4965 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building GRU model with self-attention...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 gru (GRU)                   (None, 5, 50)             14550     
                                                                 
 gru_1 (GRU)                 (None, 5, 50)             15300     
                                                                 
 gru_2 (GRU)                 (None, 5, 50)             15300     
                                                                 
 self_attention (SelfAttenti  (None, 50)               6656      
 on)                                                             
                                                                 
 dense (Dense)               (None, 25)                1275      
                                                                 
 dense_1 (Dense)             (None, 1)                 26        
                                                                 
=================================================================
Total params: 53,107
Trainable params: 53,107
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 2:34 - loss: 0.3039 2/27 [=>............................] - ETA: 1s - loss: 0.2601   3/27 [==>...........................] - ETA: 1s - loss: 0.2419 4/27 [===>..........................] - ETA: 1s - loss: 0.2232 5/27 [====>.........................] - ETA: 1s - loss: 0.2135 6/27 [=====>........................] - ETA: 1s - loss: 0.2009 7/27 [======>.......................] - ETA: 1s - loss: 0.1847 8/27 [=======>......................] - ETA: 1s - loss: 0.1688 9/27 [=========>....................] - ETA: 1s - loss: 0.153710/27 [==========>...................] - ETA: 1s - loss: 0.145311/27 [===========>..................] - ETA: 1s - loss: 0.139712/27 [============>.................] - ETA: 1s - loss: 0.133713/27 [=============>................] - ETA: 0s - loss: 0.127314/27 [==============>...............] - ETA: 0s - loss: 0.122915/27 [===============>..............] - ETA: 0s - loss: 0.118816/27 [================>.............] - ETA: 0s - loss: 0.114317/27 [=================>............] - ETA: 0s - loss: 0.110218/27 [===================>..........] - ETA: 0s - loss: 0.106319/27 [====================>.........] - ETA: 0s - loss: 0.104220/27 [=====================>........] - ETA: 0s - loss: 0.102921/27 [======================>.......] - ETA: 0s - loss: 0.100422/27 [=======================>......] - ETA: 0s - loss: 0.098523/27 [========================>.....] - ETA: 0s - loss: 0.096824/27 [=========================>....] - ETA: 0s - loss: 0.095325/27 [==========================>...] - ETA: 0s - loss: 0.093726/27 [===========================>..] - ETA: 0s - loss: 0.091927/27 [==============================] - ETA: 0s - loss: 0.091427/27 [==============================] - 9s 102ms/step - loss: 0.0914 - val_loss: 0.0269 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0340 2/27 [=>............................] - ETA: 1s - loss: 0.0273 3/27 [==>...........................] - ETA: 1s - loss: 0.0360 4/27 [===>..........................] - ETA: 1s - loss: 0.0374 5/27 [====>.........................] - ETA: 1s - loss: 0.0364 6/27 [=====>........................] - ETA: 1s - loss: 0.0335 7/27 [======>.......................] - ETA: 1s - loss: 0.0367 8/27 [=======>......................] - ETA: 1s - loss: 0.0368 9/27 [=========>....................] - ETA: 1s - loss: 0.037910/27 [==========>...................] - ETA: 1s - loss: 0.037511/27 [===========>..................] - ETA: 1s - loss: 0.037312/27 [============>.................] - ETA: 1s - loss: 0.034913/27 [=============>................] - ETA: 0s - loss: 0.035114/27 [==============>...............] - ETA: 0s - loss: 0.035015/27 [===============>..............] - ETA: 0s - loss: 0.035716/27 [================>.............] - ETA: 0s - loss: 0.037717/27 [=================>............] - ETA: 0s - loss: 0.038218/27 [===================>..........] - ETA: 0s - loss: 0.038119/27 [====================>.........] - ETA: 0s - loss: 0.037520/27 [=====================>........] - ETA: 0s - loss: 0.037521/27 [======================>.......] - ETA: 0s - loss: 0.037822/27 [=======================>......] - ETA: 0s - loss: 0.039223/27 [========================>.....] - ETA: 0s - loss: 0.039424/27 [=========================>....] - ETA: 0s - loss: 0.039325/27 [==========================>...] - ETA: 0s - loss: 0.039526/27 [===========================>..] - ETA: 0s - loss: 0.039727/27 [==============================] - ETA: 0s - loss: 0.039927/27 [==============================] - 2s 73ms/step - loss: 0.0399 - val_loss: 0.0075 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0310 2/27 [=>............................] - ETA: 1s - loss: 0.0367 3/27 [==>...........................] - ETA: 1s - loss: 0.0343 4/27 [===>..........................] - ETA: 1s - loss: 0.0306 5/27 [====>.........................] - ETA: 1s - loss: 0.0361 6/27 [=====>........................] - ETA: 1s - loss: 0.0372 7/27 [======>.......................] - ETA: 1s - loss: 0.0404 8/27 [=======>......................] - ETA: 1s - loss: 0.0416 9/27 [=========>....................] - ETA: 1s - loss: 0.040210/27 [==========>...................] - ETA: 1s - loss: 0.037511/27 [===========>..................] - ETA: 1s - loss: 0.037912/27 [============>.................] - ETA: 1s - loss: 0.037213/27 [=============>................] - ETA: 0s - loss: 0.036814/27 [==============>...............] - ETA: 0s - loss: 0.037015/27 [===============>..............] - ETA: 0s - loss: 0.036316/27 [================>.............] - ETA: 0s - loss: 0.037817/27 [=================>............] - ETA: 0s - loss: 0.036718/27 [===================>..........] - ETA: 0s - loss: 0.036819/27 [====================>.........] - ETA: 0s - loss: 0.036020/27 [=====================>........] - ETA: 0s - loss: 0.035321/27 [======================>.......] - ETA: 0s - loss: 0.035422/27 [=======================>......] - ETA: 0s - loss: 0.035323/27 [========================>.....] - ETA: 0s - loss: 0.035524/27 [=========================>....] - ETA: 0s - loss: 0.036725/27 [==========================>...] - ETA: 0s - loss: 0.036526/27 [===========================>..] - ETA: 0s - loss: 0.036127/27 [==============================] - ETA: 0s - loss: 0.036027/27 [==============================] - 2s 76ms/step - loss: 0.0360 - val_loss: 7.9492e-04 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0227 2/27 [=>............................] - ETA: 1s - loss: 0.0237 3/27 [==>...........................] - ETA: 1s - loss: 0.0358 4/27 [===>..........................] - ETA: 1s - loss: 0.0372 5/27 [====>.........................] - ETA: 1s - loss: 0.0378 6/27 [=====>........................] - ETA: 1s - loss: 0.0381 7/27 [======>.......................] - ETA: 1s - loss: 0.0369 8/27 [=======>......................] - ETA: 1s - loss: 0.0401 9/27 [=========>....................] - ETA: 1s - loss: 0.037810/27 [==========>...................] - ETA: 1s - loss: 0.035511/27 [===========>..................] - ETA: 1s - loss: 0.035012/27 [============>.................] - ETA: 1s - loss: 0.033413/27 [=============>................] - ETA: 0s - loss: 0.033814/27 [==============>...............] - ETA: 0s - loss: 0.033615/27 [===============>..............] - ETA: 0s - loss: 0.032416/27 [================>.............] - ETA: 0s - loss: 0.034417/27 [=================>............] - ETA: 0s - loss: 0.035818/27 [===================>..........] - ETA: 0s - loss: 0.035819/27 [====================>.........] - ETA: 0s - loss: 0.036220/27 [=====================>........] - ETA: 0s - loss: 0.037221/27 [======================>.......] - ETA: 0s - loss: 0.037122/27 [=======================>......] - ETA: 0s - loss: 0.036323/27 [========================>.....] - ETA: 0s - loss: 0.036424/27 [=========================>....] - ETA: 0s - loss: 0.036625/27 [==========================>...] - ETA: 0s - loss: 0.036926/27 [===========================>..] - ETA: 0s - loss: 0.036227/27 [==============================] - ETA: 0s - loss: 0.036227/27 [==============================] - 2s 73ms/step - loss: 0.0362 - val_loss: 1.7995e-04 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0413 2/27 [=>............................] - ETA: 1s - loss: 0.0492 3/27 [==>...........................] - ETA: 1s - loss: 0.0424 4/27 [===>..........................] - ETA: 1s - loss: 0.0391 5/27 [====>.........................] - ETA: 1s - loss: 0.0407 6/27 [=====>........................] - ETA: 1s - loss: 0.0420 7/27 [======>.......................] - ETA: 1s - loss: 0.0416 8/27 [=======>......................] - ETA: 1s - loss: 0.0421 9/27 [=========>....................] - ETA: 1s - loss: 0.042010/27 [==========>...................] - ETA: 1s - loss: 0.041511/27 [===========>..................] - ETA: 1s - loss: 0.041612/27 [============>.................] - ETA: 1s - loss: 0.040413/27 [=============>................] - ETA: 0s - loss: 0.040014/27 [==============>...............] - ETA: 0s - loss: 0.039415/27 [===============>..............] - ETA: 0s - loss: 0.039916/27 [================>.............] - ETA: 0s - loss: 0.039417/27 [=================>............] - ETA: 0s - loss: 0.038918/27 [===================>..........] - ETA: 0s - loss: 0.039119/27 [====================>.........] - ETA: 0s - loss: 0.039320/27 [=====================>........] - ETA: 0s - loss: 0.038321/27 [======================>.......] - ETA: 0s - loss: 0.038822/27 [=======================>......] - ETA: 0s - loss: 0.038023/27 [========================>.....] - ETA: 0s - loss: 0.037524/27 [=========================>....] - ETA: 0s - loss: 0.037125/27 [==========================>...] - ETA: 0s - loss: 0.036226/27 [===========================>..] - ETA: 0s - loss: 0.035927/27 [==============================] - ETA: 0s - loss: 0.035827/27 [==============================] - 2s 73ms/step - loss: 0.0358 - val_loss: 6.9856e-04 - lr: 0.0010
Epoch 6/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0323 2/27 [=>............................] - ETA: 1s - loss: 0.0288 3/27 [==>...........................] - ETA: 1s - loss: 0.0304 4/27 [===>..........................] - ETA: 1s - loss: 0.0330 5/27 [====>.........................] - ETA: 1s - loss: 0.0318 6/27 [=====>........................] - ETA: 1s - loss: 0.0309 7/27 [======>.......................] - ETA: 1s - loss: 0.0298 8/27 [=======>......................] - ETA: 1s - loss: 0.0299 9/27 [=========>....................] - ETA: 1s - loss: 0.032610/27 [==========>...................] - ETA: 1s - loss: 0.031911/27 [===========>..................] - ETA: 1s - loss: 0.031212/27 [============>.................] - ETA: 1s - loss: 0.031813/27 [=============>................] - ETA: 0s - loss: 0.032214/27 [==============>...............] - ETA: 0s - loss: 0.033015/27 [===============>..............] - ETA: 0s - loss: 0.033916/27 [================>.............] - ETA: 0s - loss: 0.034017/27 [=================>............] - ETA: 0s - loss: 0.034518/27 [===================>..........] - ETA: 0s - loss: 0.034519/27 [====================>.........] - ETA: 0s - loss: 0.033620/27 [=====================>........] - ETA: 0s - loss: 0.034021/27 [======================>.......] - ETA: 0s - loss: 0.033322/27 [=======================>......] - ETA: 0s - loss: 0.033223/27 [========================>.....] - ETA: 0s - loss: 0.032824/27 [=========================>....] - ETA: 0s - loss: 0.033925/27 [==========================>...] - ETA: 0s - loss: 0.035026/27 [===========================>..] - ETA: 0s - loss: 0.034527/27 [==============================] - ETA: 0s - loss: 0.034327/27 [==============================] - 2s 73ms/step - loss: 0.0343 - val_loss: 0.0049 - lr: 0.0010
Epoch 7/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0233 2/27 [=>............................] - ETA: 1s - loss: 0.0258 3/27 [==>...........................] - ETA: 1s - loss: 0.0234 4/27 [===>..........................] - ETA: 1s - loss: 0.0274 5/27 [====>.........................] - ETA: 1s - loss: 0.0288 6/27 [=====>........................] - ETA: 1s - loss: 0.0334 7/27 [======>.......................] - ETA: 1s - loss: 0.0315 8/27 [=======>......................] - ETA: 1s - loss: 0.0306 9/27 [=========>....................] - ETA: 1s - loss: 0.030510/27 [==========>...................] - ETA: 1s - loss: 0.032311/27 [===========>..................] - ETA: 1s - loss: 0.033212/27 [============>.................] - ETA: 1s - loss: 0.035113/27 [=============>................] - ETA: 0s - loss: 0.036114/27 [==============>...............] - ETA: 0s - loss: 0.035815/27 [===============>..............] - ETA: 0s - loss: 0.036516/27 [================>.............] - ETA: 0s - loss: 0.035517/27 [=================>............] - ETA: 0s - loss: 0.035018/27 [===================>..........] - ETA: 0s - loss: 0.034919/27 [====================>.........] - ETA: 0s - loss: 0.035220/27 [=====================>........] - ETA: 0s - loss: 0.034721/27 [======================>.......] - ETA: 0s - loss: 0.034722/27 [=======================>......] - ETA: 0s - loss: 0.034723/27 [========================>.....] - ETA: 0s - loss: 0.034824/27 [=========================>....] - ETA: 0s - loss: 0.034825/27 [==========================>...] - ETA: 0s - loss: 0.035526/27 [===========================>..] - ETA: 0s - loss: 0.035627/27 [==============================] - ETA: 0s - loss: 0.035527/27 [==============================] - 2s 74ms/step - loss: 0.0355 - val_loss: 0.0011 - lr: 5.0000e-04
1/5 [=====>........................] - ETA: 0s - loss: 5.6931e-045/5 [==============================] - ETA: 0s - loss: 0.0016    5/5 [==============================] - 0s 13ms/step - loss: 0.0016
Test Loss: 0.0015832731733098626
Saved model as forecasting_models_v5/model_gru_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for GRU model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 778ms/step
Predicted QoE for the next time step: 93.7263496717298
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/gru_deep.h5
Completed at Τετ 09 Απρ 2025 01:52:57 μμ EEST
=====================================================

=====================================================
Training gru model with config: wide
Starting at Τετ 09 Απρ 2025 01:52:57 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type gru                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --hidden_units 100 --attention_units 128
2025-04-09 13:52:57.859656: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:52:58.014718: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:52:58.596241: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:52:58.596335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:52:58.596345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:53:01.270128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:53:01.954531: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:53:01.954555: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:53:01.954695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4954 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building GRU model with self-attention...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 gru (GRU)                   (None, 5, 100)            44100     
                                                                 
 gru_1 (GRU)                 (None, 5, 100)            60600     
                                                                 
 self_attention (SelfAttenti  (None, 100)              13056     
 on)                                                             
                                                                 
 dense (Dense)               (None, 25)                2525      
                                                                 
 dense_1 (Dense)             (None, 1)                 26        
                                                                 
=================================================================
Total params: 120,307
Trainable params: 120,307
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 1:55 - loss: 0.2938 2/27 [=>............................] - ETA: 1s - loss: 0.2392   4/27 [===>..........................] - ETA: 1s - loss: 0.2179 6/27 [=====>........................] - ETA: 0s - loss: 0.1766 8/27 [=======>......................] - ETA: 0s - loss: 0.155510/27 [==========>...................] - ETA: 0s - loss: 0.136212/27 [============>.................] - ETA: 0s - loss: 0.126414/27 [==============>...............] - ETA: 0s - loss: 0.113116/27 [================>.............] - ETA: 0s - loss: 0.102818/27 [===================>..........] - ETA: 0s - loss: 0.094120/27 [=====================>........] - ETA: 0s - loss: 0.088421/27 [======================>.......] - ETA: 0s - loss: 0.086323/27 [========================>.....] - ETA: 0s - loss: 0.084025/27 [==========================>...] - ETA: 0s - loss: 0.080627/27 [==============================] - ETA: 0s - loss: 0.078827/27 [==============================] - 6s 74ms/step - loss: 0.0788 - val_loss: 0.0026 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0310 3/27 [==>...........................] - ETA: 1s - loss: 0.0307 5/27 [====>.........................] - ETA: 0s - loss: 0.0362 7/27 [======>.......................] - ETA: 0s - loss: 0.0379 9/27 [=========>....................] - ETA: 0s - loss: 0.037311/27 [===========>..................] - ETA: 0s - loss: 0.037513/27 [=============>................] - ETA: 0s - loss: 0.042215/27 [===============>..............] - ETA: 0s - loss: 0.041616/27 [================>.............] - ETA: 0s - loss: 0.040517/27 [=================>............] - ETA: 0s - loss: 0.040018/27 [===================>..........] - ETA: 0s - loss: 0.038720/27 [=====================>........] - ETA: 0s - loss: 0.038121/27 [======================>.......] - ETA: 0s - loss: 0.037223/27 [========================>.....] - ETA: 0s - loss: 0.036025/27 [==========================>...] - ETA: 0s - loss: 0.037227/27 [==============================] - ETA: 0s - loss: 0.036927/27 [==============================] - 1s 51ms/step - loss: 0.0369 - val_loss: 0.0012 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0267 2/27 [=>............................] - ETA: 1s - loss: 0.0423 3/27 [==>...........................] - ETA: 1s - loss: 0.0415 5/27 [====>.........................] - ETA: 1s - loss: 0.0378 7/27 [======>.......................] - ETA: 0s - loss: 0.0375 9/27 [=========>....................] - ETA: 0s - loss: 0.034411/27 [===========>..................] - ETA: 0s - loss: 0.034713/27 [=============>................] - ETA: 0s - loss: 0.035915/27 [===============>..............] - ETA: 0s - loss: 0.035817/27 [=================>............] - ETA: 0s - loss: 0.035619/27 [====================>.........] - ETA: 0s - loss: 0.037421/27 [======================>.......] - ETA: 0s - loss: 0.036823/27 [========================>.....] - ETA: 0s - loss: 0.036824/27 [=========================>....] - ETA: 0s - loss: 0.036425/27 [==========================>...] - ETA: 0s - loss: 0.036527/27 [==============================] - ETA: 0s - loss: 0.036127/27 [==============================] - 1s 51ms/step - loss: 0.0361 - val_loss: 4.7128e-04 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0437 2/27 [=>............................] - ETA: 1s - loss: 0.0376 4/27 [===>..........................] - ETA: 1s - loss: 0.0365 5/27 [====>.........................] - ETA: 1s - loss: 0.0354 6/27 [=====>........................] - ETA: 1s - loss: 0.0355 7/27 [======>.......................] - ETA: 1s - loss: 0.0377 8/27 [=======>......................] - ETA: 0s - loss: 0.0382 9/27 [=========>....................] - ETA: 0s - loss: 0.037410/27 [==========>...................] - ETA: 0s - loss: 0.041511/27 [===========>..................] - ETA: 0s - loss: 0.042212/27 [============>.................] - ETA: 0s - loss: 0.039913/27 [=============>................] - ETA: 0s - loss: 0.039214/27 [==============>...............] - ETA: 0s - loss: 0.039216/27 [================>.............] - ETA: 0s - loss: 0.038918/27 [===================>..........] - ETA: 0s - loss: 0.037520/27 [=====================>........] - ETA: 0s - loss: 0.037422/27 [=======================>......] - ETA: 0s - loss: 0.036324/27 [=========================>....] - ETA: 0s - loss: 0.034926/27 [===========================>..] - ETA: 0s - loss: 0.036027/27 [==============================] - 1s 53ms/step - loss: 0.0359 - val_loss: 3.8988e-04 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0327 2/27 [=>............................] - ETA: 1s - loss: 0.0366 3/27 [==>...........................] - ETA: 1s - loss: 0.0395 5/27 [====>.........................] - ETA: 1s - loss: 0.0379 6/27 [=====>........................] - ETA: 1s - loss: 0.0369 8/27 [=======>......................] - ETA: 0s - loss: 0.038510/27 [==========>...................] - ETA: 0s - loss: 0.037111/27 [===========>..................] - ETA: 0s - loss: 0.036612/27 [============>.................] - ETA: 0s - loss: 0.035113/27 [=============>................] - ETA: 0s - loss: 0.033615/27 [===============>..............] - ETA: 0s - loss: 0.033817/27 [=================>............] - ETA: 0s - loss: 0.033719/27 [====================>.........] - ETA: 0s - loss: 0.033620/27 [=====================>........] - ETA: 0s - loss: 0.033321/27 [======================>.......] - ETA: 0s - loss: 0.032723/27 [========================>.....] - ETA: 0s - loss: 0.034325/27 [==========================>...] - ETA: 0s - loss: 0.034627/27 [==============================] - ETA: 0s - loss: 0.034927/27 [==============================] - 1s 52ms/step - loss: 0.0349 - val_loss: 0.0032 - lr: 0.0010
Epoch 6/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0330 3/27 [==>...........................] - ETA: 1s - loss: 0.0309 5/27 [====>.........................] - ETA: 1s - loss: 0.0341 6/27 [=====>........................] - ETA: 1s - loss: 0.0335 8/27 [=======>......................] - ETA: 0s - loss: 0.032610/27 [==========>...................] - ETA: 0s - loss: 0.033812/27 [============>.................] - ETA: 0s - loss: 0.033714/27 [==============>...............] - ETA: 0s - loss: 0.033816/27 [================>.............] - ETA: 0s - loss: 0.035618/27 [===================>..........] - ETA: 0s - loss: 0.037619/27 [====================>.........] - ETA: 0s - loss: 0.037721/27 [======================>.......] - ETA: 0s - loss: 0.036923/27 [========================>.....] - ETA: 0s - loss: 0.036025/27 [==========================>...] - ETA: 0s - loss: 0.035027/27 [==============================] - ETA: 0s - loss: 0.035327/27 [==============================] - 1s 51ms/step - loss: 0.0353 - val_loss: 0.0021 - lr: 5.0000e-04
Epoch 7/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0692 3/27 [==>...........................] - ETA: 1s - loss: 0.0449 5/27 [====>.........................] - ETA: 1s - loss: 0.0421 7/27 [======>.......................] - ETA: 0s - loss: 0.0412 9/27 [=========>....................] - ETA: 0s - loss: 0.039811/27 [===========>..................] - ETA: 0s - loss: 0.038312/27 [============>.................] - ETA: 0s - loss: 0.036914/27 [==============>...............] - ETA: 0s - loss: 0.036916/27 [================>.............] - ETA: 0s - loss: 0.036017/27 [=================>............] - ETA: 0s - loss: 0.036618/27 [===================>..........] - ETA: 0s - loss: 0.035920/27 [=====================>........] - ETA: 0s - loss: 0.034922/27 [=======================>......] - ETA: 0s - loss: 0.035424/27 [=========================>....] - ETA: 0s - loss: 0.034226/27 [===========================>..] - ETA: 0s - loss: 0.034927/27 [==============================] - 1s 53ms/step - loss: 0.0348 - val_loss: 2.8148e-04 - lr: 5.0000e-04
Epoch 8/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0471 2/27 [=>............................] - ETA: 1s - loss: 0.0366 4/27 [===>..........................] - ETA: 1s - loss: 0.0407 5/27 [====>.........................] - ETA: 1s - loss: 0.0387 7/27 [======>.......................] - ETA: 0s - loss: 0.0369 9/27 [=========>....................] - ETA: 0s - loss: 0.037310/27 [==========>...................] - ETA: 0s - loss: 0.034212/27 [============>.................] - ETA: 0s - loss: 0.034313/27 [=============>................] - ETA: 0s - loss: 0.033515/27 [===============>..............] - ETA: 0s - loss: 0.033316/27 [================>.............] - ETA: 0s - loss: 0.035318/27 [===================>..........] - ETA: 0s - loss: 0.034320/27 [=====================>........] - ETA: 0s - loss: 0.033721/27 [======================>.......] - ETA: 0s - loss: 0.033723/27 [========================>.....] - ETA: 0s - loss: 0.034125/27 [==========================>...] - ETA: 0s - loss: 0.033427/27 [==============================] - ETA: 0s - loss: 0.034127/27 [==============================] - 1s 52ms/step - loss: 0.0341 - val_loss: 8.3309e-04 - lr: 5.0000e-04
Epoch 9/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0559 3/27 [==>...........................] - ETA: 1s - loss: 0.0340 5/27 [====>.........................] - ETA: 1s - loss: 0.0381 7/27 [======>.......................] - ETA: 0s - loss: 0.0379 9/27 [=========>....................] - ETA: 0s - loss: 0.036810/27 [==========>...................] - ETA: 0s - loss: 0.037812/27 [============>.................] - ETA: 0s - loss: 0.037414/27 [==============>...............] - ETA: 0s - loss: 0.038116/27 [================>.............] - ETA: 0s - loss: 0.037217/27 [=================>............] - ETA: 0s - loss: 0.036418/27 [===================>..........] - ETA: 0s - loss: 0.035119/27 [====================>.........] - ETA: 0s - loss: 0.036620/27 [=====================>........] - ETA: 0s - loss: 0.036622/27 [=======================>......] - ETA: 0s - loss: 0.035723/27 [========================>.....] - ETA: 0s - loss: 0.036624/27 [=========================>....] - ETA: 0s - loss: 0.036225/27 [==========================>...] - ETA: 0s - loss: 0.035827/27 [==============================] - ETA: 0s - loss: 0.034927/27 [==============================] - 1s 52ms/step - loss: 0.0349 - val_loss: 4.1836e-04 - lr: 5.0000e-04
Epoch 10/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0477 3/27 [==>...........................] - ETA: 1s - loss: 0.0278 4/27 [===>..........................] - ETA: 1s - loss: 0.0263 6/27 [=====>........................] - ETA: 1s - loss: 0.0313 7/27 [======>.......................] - ETA: 1s - loss: 0.0313 8/27 [=======>......................] - ETA: 0s - loss: 0.0294 9/27 [=========>....................] - ETA: 0s - loss: 0.032610/27 [==========>...................] - ETA: 0s - loss: 0.032212/27 [============>.................] - ETA: 0s - loss: 0.033313/27 [=============>................] - ETA: 0s - loss: 0.034415/27 [===============>..............] - ETA: 0s - loss: 0.033917/27 [=================>............] - ETA: 0s - loss: 0.035219/27 [====================>.........] - ETA: 0s - loss: 0.035821/27 [======================>.......] - ETA: 0s - loss: 0.034623/27 [========================>.....] - ETA: 0s - loss: 0.036124/27 [=========================>....] - ETA: 0s - loss: 0.035726/27 [===========================>..] - ETA: 0s - loss: 0.034927/27 [==============================] - ETA: 0s - loss: 0.034827/27 [==============================] - 1s 54ms/step - loss: 0.0348 - val_loss: 9.5763e-04 - lr: 2.5000e-04
1/5 [=====>........................] - ETA: 0s - loss: 3.5795e-045/5 [==============================] - 0s 11ms/step - loss: 6.3686e-04
Test Loss: 0.0006368560716509819
Saved model as forecasting_models_v5/model_gru_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for GRU model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 555ms/step
Predicted QoE for the next time step: 98.70435404275894
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/gru_wide.h5
Completed at Τετ 09 Απρ 2025 01:53:25 μμ EEST
=====================================================

=====================================================
Training gru model with config: bidirectional
Starting at Τετ 09 Απρ 2025 01:53:25 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type gru                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --bidirectional --attention_units 128
2025-04-09 13:53:25.505079: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:53:25.688333: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:53:26.338329: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:53:26.338427: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:53:26.338437: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:53:29.093357: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:53:29.777789: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:53:29.777813: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:53:29.777956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4978 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building GRU model with self-attention...
Traceback (most recent call last):
  File "timeseries_forecasting_models_v5.py", line 889, in <module>
    main()
  File "timeseries_forecasting_models_v5.py", line 720, in main
    model.summary()
  File "/home/dimitris/.local/lib/python3.8/site-packages/keras/engine/training.py", line 3214, in summary
    raise ValueError(
ValueError: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.
Warning: Original model file not found at /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/model_gru_with_attention.h5
Directory contents:
total 8216
drwxrwxr-x  2 dimitris dimitris    4096 Απρ   9 13:53 .
drwxrwxr-x 15 dimitris dimitris    4096 Απρ   9 13:43 ..
-rw-rw-r--  1 dimitris dimitris  233792 Απρ   9 13:49 dnn_basic.h5
-rw-rw-r--  1 dimitris dimitris  519208 Απρ   9 13:49 dnn_deep.h5
-rw-rw-r--  1 dimitris dimitris  233792 Απρ   9 13:49 dnn_with_elu.h5
-rw-rw-r--  1 dimitris dimitris  233792 Απρ   9 13:50 dnn_with_high_dropout.h5
-rw-rw-r--  1 dimitris dimitris  514616 Απρ   9 13:52 gru_basic.h5
-rw-rw-r--  1 dimitris dimitris  709264 Απρ   9 13:52 gru_deep.h5
-rw-rw-r--  1 dimitris dimitris 1504352 Απρ   9 13:53 gru_wide.h5
-rw-rw-r--  1 dimitris dimitris   22064 Απρ   9 13:48 linear_basic.h5
-rw-rw-r--  1 dimitris dimitris   22064 Απρ   9 13:49 linear_with_elastic_net.h5
-rw-rw-r--  1 dimitris dimitris   22064 Απρ   9 13:49 linear_with_l1_reg.h5
-rw-rw-r--  1 dimitris dimitris   22064 Απρ   9 13:49 linear_with_l2_reg.h5
-rw-rw-r--  1 dimitris dimitris  628760 Απρ   9 13:50 lstm_basic.h5
-rw-rw-r--  1 dimitris dimitris  881952 Απρ   9 13:50 lstm_deep.h5
-rw-rw-r--  1 dimitris dimitris 1914264 Απρ   9 13:51 lstm_wide.h5
-rw-rw-r--  1 dimitris dimitris  628760 Απρ   9 13:51 lstm_with_stats.h5
-rw-rw-r--  1 dimitris dimitris    3463 Απρ   9 13:53 scaler.save
-rw-rw-r--  1 dimitris dimitris  266213 Απρ   9 13:53 training_log.txt
Completed at Τετ 09 Απρ 2025 01:53:32 μμ EEST
=====================================================

=====================================================
Training gru model with config: with_stats
Starting at Τετ 09 Απρ 2025 01:53:32 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type gru                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --attention_units 128
2025-04-09 13:53:32.781967: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:53:32.926601: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:53:33.508954: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:53:33.509047: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:53:33.509057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:53:36.158215: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:53:36.864067: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:53:36.864103: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:53:36.864218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4980 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building GRU model with self-attention...
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 gru (GRU)                   (None, 5, 50)             14550     
                                                                 
 gru_1 (GRU)                 (None, 5, 50)             15300     
                                                                 
 self_attention (SelfAttenti  (None, 50)               6656      
 on)                                                             
                                                                 
 dense (Dense)               (None, 25)                1275      
                                                                 
 dense_1 (Dense)             (None, 1)                 26        
                                                                 
=================================================================
Total params: 37,807
Trainable params: 37,807
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 1:50 - loss: 0.2624 2/27 [=>............................] - ETA: 1s - loss: 0.2629   4/27 [===>..........................] - ETA: 1s - loss: 0.2161 6/27 [=====>........................] - ETA: 0s - loss: 0.1825 7/27 [======>.......................] - ETA: 0s - loss: 0.1677 8/27 [=======>......................] - ETA: 0s - loss: 0.156010/27 [==========>...................] - ETA: 0s - loss: 0.131712/27 [============>.................] - ETA: 0s - loss: 0.114414/27 [==============>...............] - ETA: 0s - loss: 0.106016/27 [================>.............] - ETA: 0s - loss: 0.103118/27 [===================>..........] - ETA: 0s - loss: 0.095620/27 [=====================>........] - ETA: 0s - loss: 0.090921/27 [======================>.......] - ETA: 0s - loss: 0.089123/27 [========================>.....] - ETA: 0s - loss: 0.085925/27 [==========================>...] - ETA: 0s - loss: 0.083427/27 [==============================] - ETA: 0s - loss: 0.081827/27 [==============================] - 6s 74ms/step - loss: 0.0818 - val_loss: 0.0140 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0428 3/27 [==>...........................] - ETA: 1s - loss: 0.0402 5/27 [====>.........................] - ETA: 0s - loss: 0.0366 7/27 [======>.......................] - ETA: 0s - loss: 0.0368 9/27 [=========>....................] - ETA: 0s - loss: 0.036711/27 [===========>..................] - ETA: 0s - loss: 0.039413/27 [=============>................] - ETA: 0s - loss: 0.037214/27 [==============>...............] - ETA: 0s - loss: 0.039516/27 [================>.............] - ETA: 0s - loss: 0.039018/27 [===================>..........] - ETA: 0s - loss: 0.036819/27 [====================>.........] - ETA: 0s - loss: 0.038421/27 [======================>.......] - ETA: 0s - loss: 0.038523/27 [========================>.....] - ETA: 0s - loss: 0.038625/27 [==========================>...] - ETA: 0s - loss: 0.037327/27 [==============================] - ETA: 0s - loss: 0.036727/27 [==============================] - 1s 50ms/step - loss: 0.0367 - val_loss: 5.9157e-04 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0457 3/27 [==>...........................] - ETA: 1s - loss: 0.0426 5/27 [====>.........................] - ETA: 1s - loss: 0.0366 7/27 [======>.......................] - ETA: 0s - loss: 0.0374 9/27 [=========>....................] - ETA: 0s - loss: 0.039111/27 [===========>..................] - ETA: 0s - loss: 0.037513/27 [=============>................] - ETA: 0s - loss: 0.037414/27 [==============>...............] - ETA: 0s - loss: 0.037216/27 [================>.............] - ETA: 0s - loss: 0.035218/27 [===================>..........] - ETA: 0s - loss: 0.037120/27 [=====================>........] - ETA: 0s - loss: 0.035922/27 [=======================>......] - ETA: 0s - loss: 0.035323/27 [========================>.....] - ETA: 0s - loss: 0.035724/27 [=========================>....] - ETA: 0s - loss: 0.035526/27 [===========================>..] - ETA: 0s - loss: 0.036627/27 [==============================] - 1s 51ms/step - loss: 0.0365 - val_loss: 3.9677e-04 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0415 2/27 [=>............................] - ETA: 1s - loss: 0.0285 4/27 [===>..........................] - ETA: 1s - loss: 0.0398 6/27 [=====>........................] - ETA: 1s - loss: 0.0372 7/27 [======>.......................] - ETA: 0s - loss: 0.0350 9/27 [=========>....................] - ETA: 0s - loss: 0.033411/27 [===========>..................] - ETA: 0s - loss: 0.034313/27 [=============>................] - ETA: 0s - loss: 0.033915/27 [===============>..............] - ETA: 0s - loss: 0.034916/27 [================>.............] - ETA: 0s - loss: 0.034418/27 [===================>..........] - ETA: 0s - loss: 0.035820/27 [=====================>........] - ETA: 0s - loss: 0.036522/27 [=======================>......] - ETA: 0s - loss: 0.034824/27 [=========================>....] - ETA: 0s - loss: 0.034826/27 [===========================>..] - ETA: 0s - loss: 0.034027/27 [==============================] - 1s 50ms/step - loss: 0.0339 - val_loss: 6.7013e-04 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0085 2/27 [=>............................] - ETA: 1s - loss: 0.0307 3/27 [==>...........................] - ETA: 1s - loss: 0.0360 4/27 [===>..........................] - ETA: 1s - loss: 0.0342 5/27 [====>.........................] - ETA: 1s - loss: 0.0340 7/27 [======>.......................] - ETA: 1s - loss: 0.0368 8/27 [=======>......................] - ETA: 0s - loss: 0.0359 9/27 [=========>....................] - ETA: 0s - loss: 0.038011/27 [===========>..................] - ETA: 0s - loss: 0.037713/27 [=============>................] - ETA: 0s - loss: 0.037815/27 [===============>..............] - ETA: 0s - loss: 0.037917/27 [=================>............] - ETA: 0s - loss: 0.036919/27 [====================>.........] - ETA: 0s - loss: 0.036421/27 [======================>.......] - ETA: 0s - loss: 0.037122/27 [=======================>......] - ETA: 0s - loss: 0.037523/27 [========================>.....] - ETA: 0s - loss: 0.036624/27 [=========================>....] - ETA: 0s - loss: 0.036026/27 [===========================>..] - ETA: 0s - loss: 0.035527/27 [==============================] - 1s 52ms/step - loss: 0.0355 - val_loss: 3.6623e-04 - lr: 0.0010
Epoch 6/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0296 3/27 [==>...........................] - ETA: 1s - loss: 0.0370 5/27 [====>.........................] - ETA: 0s - loss: 0.0342 7/27 [======>.......................] - ETA: 0s - loss: 0.0319 9/27 [=========>....................] - ETA: 0s - loss: 0.032411/27 [===========>..................] - ETA: 0s - loss: 0.031913/27 [=============>................] - ETA: 0s - loss: 0.031014/27 [==============>...............] - ETA: 0s - loss: 0.030516/27 [================>.............] - ETA: 0s - loss: 0.029218/27 [===================>..........] - ETA: 0s - loss: 0.029720/27 [=====================>........] - ETA: 0s - loss: 0.030921/27 [======================>.......] - ETA: 0s - loss: 0.031923/27 [========================>.....] - ETA: 0s - loss: 0.032524/27 [=========================>....] - ETA: 0s - loss: 0.033425/27 [==========================>...] - ETA: 0s - loss: 0.033527/27 [==============================] - ETA: 0s - loss: 0.033727/27 [==============================] - 1s 52ms/step - loss: 0.0337 - val_loss: 0.0040 - lr: 5.0000e-04
Epoch 7/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0251 3/27 [==>...........................] - ETA: 1s - loss: 0.0295 5/27 [====>.........................] - ETA: 0s - loss: 0.0330 7/27 [======>.......................] - ETA: 0s - loss: 0.0379 9/27 [=========>....................] - ETA: 0s - loss: 0.035910/27 [==========>...................] - ETA: 0s - loss: 0.034212/27 [============>.................] - ETA: 0s - loss: 0.034014/27 [==============>...............] - ETA: 0s - loss: 0.032516/27 [================>.............] - ETA: 0s - loss: 0.034618/27 [===================>..........] - ETA: 0s - loss: 0.032620/27 [=====================>........] - ETA: 0s - loss: 0.035422/27 [=======================>......] - ETA: 0s - loss: 0.035824/27 [=========================>....] - ETA: 0s - loss: 0.036126/27 [===========================>..] - ETA: 0s - loss: 0.035527/27 [==============================] - 1s 51ms/step - loss: 0.0353 - val_loss: 0.0024 - lr: 5.0000e-04
Epoch 8/20
 1/27 [>.............................] - ETA: 1s - loss: 0.0341 3/27 [==>...........................] - ETA: 1s - loss: 0.0353 4/27 [===>..........................] - ETA: 1s - loss: 0.0371 6/27 [=====>........................] - ETA: 1s - loss: 0.0337 8/27 [=======>......................] - ETA: 0s - loss: 0.0330 9/27 [=========>....................] - ETA: 0s - loss: 0.032410/27 [==========>...................] - ETA: 0s - loss: 0.032712/27 [============>.................] - ETA: 0s - loss: 0.033014/27 [==============>...............] - ETA: 0s - loss: 0.034716/27 [================>.............] - ETA: 0s - loss: 0.034518/27 [===================>..........] - ETA: 0s - loss: 0.033320/27 [=====================>........] - ETA: 0s - loss: 0.034322/27 [=======================>......] - ETA: 0s - loss: 0.035423/27 [========================>.....] - ETA: 0s - loss: 0.034925/27 [==========================>...] - ETA: 0s - loss: 0.033426/27 [===========================>..] - ETA: 0s - loss: 0.033927/27 [==============================] - 1s 52ms/step - loss: 0.0338 - val_loss: 6.3031e-04 - lr: 2.5000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.00155/5 [==============================] - 0s 11ms/step - loss: 0.0035
Test Loss: 0.0035041875671595335
Saved model as forecasting_models_v5/model_gru_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for GRU model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 1s 560ms/step
Predicted QoE for the next time step: 93.33556728438974
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/gru_with_stats.h5
Completed at Τετ 09 Απρ 2025 01:53:56 μμ EEST
=====================================================

=====================================================
Training transformer model with config: basic
Starting at Τετ 09 Απρ 2025 01:53:56 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type transformer                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 
2025-04-09 13:53:57.268948: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:53:57.426689: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:53:58.012199: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:53:58.012288: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:53:58.012298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:54:00.736546: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:54:01.405405: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:54:01.405439: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:54:01.405563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4975 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building Transformer model...
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 5, 45)]           0         
                                                                 
 transformer_block (Transfor  (None, 5, 45)            22564     
 merBlock)                                                       
                                                                 
 flatten (Flatten)           (None, 225)               0         
                                                                 
 dense_2 (Dense)             (None, 32)                7232      
                                                                 
 dense_3 (Dense)             (None, 1)                 33        
                                                                 
=================================================================
Total params: 29,829
Trainable params: 29,829
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 37s - loss: 2.2534 8/27 [=======>......................] - ETA: 0s - loss: 0.6093 15/27 [===============>..............] - ETA: 0s - loss: 0.382122/27 [=======================>......] - ETA: 0s - loss: 0.291727/27 [==============================] - 2s 20ms/step - loss: 0.2564 - val_loss: 0.0113 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0672 8/27 [=======>......................] - ETA: 0s - loss: 0.071315/27 [===============>..............] - ETA: 0s - loss: 0.064121/27 [======================>.......] - ETA: 0s - loss: 0.060427/27 [==============================] - 0s 11ms/step - loss: 0.0551 - val_loss: 0.0105 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0405 8/27 [=======>......................] - ETA: 0s - loss: 0.053515/27 [===============>..............] - ETA: 0s - loss: 0.047022/27 [=======================>......] - ETA: 0s - loss: 0.042927/27 [==============================] - 0s 10ms/step - loss: 0.0467 - val_loss: 0.0141 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0394 7/27 [======>.......................] - ETA: 0s - loss: 0.038313/27 [=============>................] - ETA: 0s - loss: 0.038219/27 [====================>.........] - ETA: 0s - loss: 0.037825/27 [==========================>...] - ETA: 0s - loss: 0.041427/27 [==============================] - 0s 11ms/step - loss: 0.0411 - val_loss: 0.0071 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0243 7/27 [======>.......................] - ETA: 0s - loss: 0.039314/27 [==============>...............] - ETA: 0s - loss: 0.038721/27 [======================>.......] - ETA: 0s - loss: 0.038927/27 [==============================] - ETA: 0s - loss: 0.040327/27 [==============================] - 0s 11ms/step - loss: 0.0403 - val_loss: 0.0022 - lr: 0.0010
Epoch 6/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0229 7/27 [======>.......................] - ETA: 0s - loss: 0.035613/27 [=============>................] - ETA: 0s - loss: 0.036519/27 [====================>.........] - ETA: 0s - loss: 0.037625/27 [==========================>...] - ETA: 0s - loss: 0.038127/27 [==============================] - 0s 11ms/step - loss: 0.0384 - val_loss: 0.0103 - lr: 0.0010
Epoch 7/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0446 7/27 [======>.......................] - ETA: 0s - loss: 0.038614/27 [==============>...............] - ETA: 0s - loss: 0.038320/27 [=====================>........] - ETA: 0s - loss: 0.037527/27 [==============================] - ETA: 0s - loss: 0.038127/27 [==============================] - 0s 10ms/step - loss: 0.0381 - val_loss: 0.0099 - lr: 0.0010
Epoch 8/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0344 7/27 [======>.......................] - ETA: 0s - loss: 0.040213/27 [=============>................] - ETA: 0s - loss: 0.036419/27 [====================>.........] - ETA: 0s - loss: 0.040725/27 [==========================>...] - ETA: 0s - loss: 0.039527/27 [==============================] - 0s 11ms/step - loss: 0.0397 - val_loss: 0.0021 - lr: 5.0000e-04
Epoch 9/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0328 7/27 [======>.......................] - ETA: 0s - loss: 0.032514/27 [==============>...............] - ETA: 0s - loss: 0.035520/27 [=====================>........] - ETA: 0s - loss: 0.035326/27 [===========================>..] - ETA: 0s - loss: 0.035327/27 [==============================] - 0s 11ms/step - loss: 0.0352 - val_loss: 0.0041 - lr: 5.0000e-04
Epoch 10/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0168 7/27 [======>.......................] - ETA: 0s - loss: 0.038513/27 [=============>................] - ETA: 0s - loss: 0.036519/27 [====================>.........] - ETA: 0s - loss: 0.035025/27 [==========================>...] - ETA: 0s - loss: 0.035027/27 [==============================] - 0s 11ms/step - loss: 0.0354 - val_loss: 0.0044 - lr: 2.5000e-04
Epoch 11/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0276 8/27 [=======>......................] - ETA: 0s - loss: 0.027615/27 [===============>..............] - ETA: 0s - loss: 0.032821/27 [======================>.......] - ETA: 0s - loss: 0.032927/27 [==============================] - ETA: 0s - loss: 0.033327/27 [==============================] - 0s 12ms/step - loss: 0.0333 - val_loss: 0.0035 - lr: 2.5000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.00255/5 [==============================] - 0s 4ms/step - loss: 0.0044
Test Loss: 0.004384479485452175
Saved model as forecasting_models_v5/model_transformer_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for TRANSFORMER model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 182ms/step
Predicted QoE for the next time step: 35.32586313787639
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/transformer_basic.h5
Completed at Τετ 09 Απρ 2025 01:54:09 μμ EEST
=====================================================

=====================================================
Training transformer model with config: more_heads
Starting at Τετ 09 Απρ 2025 01:54:09 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type transformer                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --num_heads 4
2025-04-09 13:54:10.213302: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:54:10.371798: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:54:10.962574: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:54:10.962655: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:54:10.962665: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:54:13.633682: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:54:14.329384: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:54:14.329420: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:54:14.329556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4983 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building Transformer model...
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 5, 45)]           0         
                                                                 
 transformer_block (Transfor  (None, 5, 45)            39034     
 merBlock)                                                       
                                                                 
 flatten (Flatten)           (None, 225)               0         
                                                                 
 dense_2 (Dense)             (None, 32)                7232      
                                                                 
 dense_3 (Dense)             (None, 1)                 33        
                                                                 
=================================================================
Total params: 46,299
Trainable params: 46,299
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 38s - loss: 0.6593 8/27 [=======>......................] - ETA: 0s - loss: 0.2798 15/27 [===============>..............] - ETA: 0s - loss: 0.202122/27 [=======================>......] - ETA: 0s - loss: 0.159827/27 [==============================] - 2s 19ms/step - loss: 0.1467 - val_loss: 0.0254 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0728 8/27 [=======>......................] - ETA: 0s - loss: 0.058915/27 [===============>..............] - ETA: 0s - loss: 0.059522/27 [=======================>......] - ETA: 0s - loss: 0.060427/27 [==============================] - 0s 10ms/step - loss: 0.0569 - val_loss: 0.0034 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0302 7/27 [======>.......................] - ETA: 0s - loss: 0.049313/27 [=============>................] - ETA: 0s - loss: 0.053719/27 [====================>.........] - ETA: 0s - loss: 0.059125/27 [==========================>...] - ETA: 0s - loss: 0.054927/27 [==============================] - 0s 11ms/step - loss: 0.0549 - val_loss: 0.0089 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0530 7/27 [======>.......................] - ETA: 0s - loss: 0.061413/27 [=============>................] - ETA: 0s - loss: 0.054919/27 [====================>.........] - ETA: 0s - loss: 0.053226/27 [===========================>..] - ETA: 0s - loss: 0.052127/27 [==============================] - 0s 11ms/step - loss: 0.0519 - val_loss: 0.0090 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0612 8/27 [=======>......................] - ETA: 0s - loss: 0.044015/27 [===============>..............] - ETA: 0s - loss: 0.046422/27 [=======================>......] - ETA: 0s - loss: 0.043727/27 [==============================] - 0s 11ms/step - loss: 0.0429 - val_loss: 0.0025 - lr: 5.0000e-04
Epoch 6/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0341 7/27 [======>.......................] - ETA: 0s - loss: 0.037413/27 [=============>................] - ETA: 0s - loss: 0.039720/27 [=====================>........] - ETA: 0s - loss: 0.039727/27 [==============================] - ETA: 0s - loss: 0.040627/27 [==============================] - 0s 11ms/step - loss: 0.0406 - val_loss: 0.0020 - lr: 5.0000e-04
Epoch 7/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0186 7/27 [======>.......................] - ETA: 0s - loss: 0.038214/27 [==============>...............] - ETA: 0s - loss: 0.038820/27 [=====================>........] - ETA: 0s - loss: 0.038826/27 [===========================>..] - ETA: 0s - loss: 0.040227/27 [==============================] - 0s 11ms/step - loss: 0.0401 - val_loss: 0.0023 - lr: 5.0000e-04
Epoch 8/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0547 8/27 [=======>......................] - ETA: 0s - loss: 0.041315/27 [===============>..............] - ETA: 0s - loss: 0.039721/27 [======================>.......] - ETA: 0s - loss: 0.038627/27 [==============================] - 0s 10ms/step - loss: 0.0379 - val_loss: 0.0020 - lr: 5.0000e-04
Epoch 9/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0157 7/27 [======>.......................] - ETA: 0s - loss: 0.037714/27 [==============>...............] - ETA: 0s - loss: 0.036320/27 [=====================>........] - ETA: 0s - loss: 0.036226/27 [===========================>..] - ETA: 0s - loss: 0.036327/27 [==============================] - 0s 11ms/step - loss: 0.0363 - val_loss: 0.0031 - lr: 2.5000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.01485/5 [==============================] - 0s 4ms/step - loss: 0.0308
Test Loss: 0.030820190906524658
Saved model as forecasting_models_v5/model_transformer_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for TRANSFORMER model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 181ms/step
Predicted QoE for the next time step: 66.14860665652394
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/transformer_more_heads.h5
Completed at Τετ 09 Απρ 2025 01:54:22 μμ EEST
=====================================================

=====================================================
Training transformer model with config: large_ff
Starting at Τετ 09 Απρ 2025 01:54:22 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type transformer                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --ff_dim 128
2025-04-09 13:54:22.478769: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:54:22.630916: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:54:23.219394: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:54:23.219518: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:54:23.219528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:54:26.001450: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:54:26.694466: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:54:26.694491: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:54:26.694622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4982 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building Transformer model...
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 5, 45)]           0         
                                                                 
 transformer_block (Transfor  (None, 5, 45)            28388     
 merBlock)                                                       
                                                                 
 flatten (Flatten)           (None, 225)               0         
                                                                 
 dense_2 (Dense)             (None, 32)                7232      
                                                                 
 dense_3 (Dense)             (None, 1)                 33        
                                                                 
=================================================================
Total params: 35,653
Trainable params: 35,653
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 40s - loss: 0.7274 8/27 [=======>......................] - ETA: 0s - loss: 0.2566 16/27 [================>.............] - ETA: 0s - loss: 0.178024/27 [=========================>....] - ETA: 0s - loss: 0.147827/27 [==============================] - 2s 19ms/step - loss: 0.1396 - val_loss: 0.0059 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0440 8/27 [=======>......................] - ETA: 0s - loss: 0.052516/27 [================>.............] - ETA: 0s - loss: 0.051123/27 [========================>.....] - ETA: 0s - loss: 0.049927/27 [==============================] - 0s 10ms/step - loss: 0.0505 - val_loss: 0.0098 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0462 7/27 [======>.......................] - ETA: 0s - loss: 0.049214/27 [==============>...............] - ETA: 0s - loss: 0.043521/27 [======================>.......] - ETA: 0s - loss: 0.043927/27 [==============================] - ETA: 0s - loss: 0.043127/27 [==============================] - 0s 11ms/step - loss: 0.0431 - val_loss: 0.0026 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0341 8/27 [=======>......................] - ETA: 0s - loss: 0.039515/27 [===============>..............] - ETA: 0s - loss: 0.040222/27 [=======================>......] - ETA: 0s - loss: 0.036927/27 [==============================] - 0s 10ms/step - loss: 0.0377 - val_loss: 0.0074 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0647 7/27 [======>.......................] - ETA: 0s - loss: 0.048513/27 [=============>................] - ETA: 0s - loss: 0.041620/27 [=====================>........] - ETA: 0s - loss: 0.040127/27 [==============================] - ETA: 0s - loss: 0.040127/27 [==============================] - 0s 10ms/step - loss: 0.0401 - val_loss: 0.0067 - lr: 0.0010
Epoch 6/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0266 8/27 [=======>......................] - ETA: 0s - loss: 0.041715/27 [===============>..............] - ETA: 0s - loss: 0.036722/27 [=======================>......] - ETA: 0s - loss: 0.036327/27 [==============================] - 0s 11ms/step - loss: 0.0359 - val_loss: 0.0027 - lr: 5.0000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.00195/5 [==============================] - 0s 4ms/step - loss: 0.0028
Test Loss: 0.0028273812495172024
Saved model as forecasting_models_v5/model_transformer_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for TRANSFORMER model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 190ms/step
Predicted QoE for the next time step: 19.281112015455363
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/transformer_large_ff.h5
Completed at Τετ 09 Απρ 2025 01:54:33 μμ EEST
=====================================================

=====================================================
Training transformer model with config: low_dropout
Starting at Τετ 09 Απρ 2025 01:54:33 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type transformer                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 --dropout_rate 0.05
2025-04-09 13:54:34.081076: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:54:34.242231: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:54:34.827974: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:54:34.828054: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:54:34.828075: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:54:37.487953: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:54:38.170849: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:54:38.170884: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:54:38.171019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4984 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building Transformer model...
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 5, 45)]           0         
                                                                 
 transformer_block (Transfor  (None, 5, 45)            22564     
 merBlock)                                                       
                                                                 
 flatten (Flatten)           (None, 225)               0         
                                                                 
 dense_2 (Dense)             (None, 32)                7232      
                                                                 
 dense_3 (Dense)             (None, 1)                 33        
                                                                 
=================================================================
Total params: 29,829
Trainable params: 29,829
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 38s - loss: 1.4357 9/27 [=========>....................] - ETA: 0s - loss: 0.3538 16/27 [================>.............] - ETA: 0s - loss: 0.248423/27 [========================>.....] - ETA: 0s - loss: 0.198727/27 [==============================] - 2s 20ms/step - loss: 0.1872 - val_loss: 0.0199 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0331 8/27 [=======>......................] - ETA: 0s - loss: 0.076515/27 [===============>..............] - ETA: 0s - loss: 0.075722/27 [=======================>......] - ETA: 0s - loss: 0.070727/27 [==============================] - 0s 10ms/step - loss: 0.0682 - val_loss: 0.0107 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0657 7/27 [======>.......................] - ETA: 0s - loss: 0.059314/27 [==============>...............] - ETA: 0s - loss: 0.056320/27 [=====================>........] - ETA: 0s - loss: 0.053626/27 [===========================>..] - ETA: 0s - loss: 0.052327/27 [==============================] - 0s 11ms/step - loss: 0.0523 - val_loss: 0.0218 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0639 7/27 [======>.......................] - ETA: 0s - loss: 0.042013/27 [=============>................] - ETA: 0s - loss: 0.043019/27 [====================>.........] - ETA: 0s - loss: 0.042826/27 [===========================>..] - ETA: 0s - loss: 0.041827/27 [==============================] - 0s 11ms/step - loss: 0.0417 - val_loss: 0.0167 - lr: 0.0010
Epoch 5/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0424 7/27 [======>.......................] - ETA: 0s - loss: 0.045814/27 [==============>...............] - ETA: 0s - loss: 0.045820/27 [=====================>........] - ETA: 0s - loss: 0.042427/27 [==============================] - ETA: 0s - loss: 0.039827/27 [==============================] - 0s 11ms/step - loss: 0.0398 - val_loss: 0.0159 - lr: 5.0000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.00775/5 [==============================] - 0s 4ms/step - loss: 0.0065
Test Loss: 0.0065358225256204605
Saved model as forecasting_models_v5/model_transformer_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for TRANSFORMER model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 186ms/step
Predicted QoE for the next time step: 27.08346905458808
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/transformer_low_dropout.h5
Completed at Τετ 09 Απρ 2025 01:54:44 μμ EEST
=====================================================

=====================================================
Training transformer model with config: with_stats
Starting at Τετ 09 Απρ 2025 01:54:44 μμ EEST
=====================================================
Command: python3 timeseries_forecasting_models_v5.py                 --data_folder ./real_dataset                 --model_type transformer                 --seq_length 5                 --epochs 20                 --batch_size 16                 --augmented                 --use_stats                 
2025-04-09 13:54:45.232700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:54:45.384511: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-09 13:54:46.014401: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:54:46.014502: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2025-04-09 13:54:46.014518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2025-04-09 13:54:48.789766: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-09 13:54:49.456398: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2025-04-09 13:54:49.456423: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0
2025-04-09 13:54:49.456564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4984 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5
Loading augmented dataset from: ./real_dataset
Using new format
Dataset shape: (659, 47)
Features: 45
Sample timestamp: 2025-04-02 12:19:54
Total sequences: 654
Input shape: (654, 5, 45)
Training samples: 523 Test samples: 131
Building Transformer model...
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 5, 45)]           0         
                                                                 
 transformer_block (Transfor  (None, 5, 45)            22564     
 merBlock)                                                       
                                                                 
 flatten (Flatten)           (None, 225)               0         
                                                                 
 dense_2 (Dense)             (None, 32)                7232      
                                                                 
 dense_3 (Dense)             (None, 1)                 33        
                                                                 
=================================================================
Total params: 29,829
Trainable params: 29,829
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
 1/27 [>.............................] - ETA: 38s - loss: 1.0381 8/27 [=======>......................] - ETA: 0s - loss: 0.3735 15/27 [===============>..............] - ETA: 0s - loss: 0.246522/27 [=======================>......] - ETA: 0s - loss: 0.196727/27 [==============================] - 2s 20ms/step - loss: 0.1754 - val_loss: 0.0194 - lr: 0.0010
Epoch 2/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0261 8/27 [=======>......................] - ETA: 0s - loss: 0.064614/27 [==============>...............] - ETA: 0s - loss: 0.055021/27 [======================>.......] - ETA: 0s - loss: 0.056527/27 [==============================] - ETA: 0s - loss: 0.055027/27 [==============================] - 0s 10ms/step - loss: 0.0550 - val_loss: 0.0488 - lr: 0.0010
Epoch 3/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0456 7/27 [======>.......................] - ETA: 0s - loss: 0.050113/27 [=============>................] - ETA: 0s - loss: 0.045319/27 [====================>.........] - ETA: 0s - loss: 0.047725/27 [==========================>...] - ETA: 0s - loss: 0.048727/27 [==============================] - 0s 11ms/step - loss: 0.0476 - val_loss: 0.0253 - lr: 0.0010
Epoch 4/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0427 8/27 [=======>......................] - ETA: 0s - loss: 0.037614/27 [==============>...............] - ETA: 0s - loss: 0.046020/27 [=====================>........] - ETA: 0s - loss: 0.044927/27 [==============================] - ETA: 0s - loss: 0.045927/27 [==============================] - 0s 11ms/step - loss: 0.0459 - val_loss: 0.0381 - lr: 5.0000e-04
1/5 [=====>........................] - ETA: 0s - loss: 0.01625/5 [==============================] - 0s 4ms/step - loss: 0.0074
Test Loss: 0.007353611756116152
Saved model as forecasting_models_v5/model_transformer_with_attention.h5
Saved scaler as forecasting_models_v5/scaler.save

Preparing sample inference example for TRANSFORMER model...
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 185ms/step
Predicted QoE for the next time step: 146.93095114190817
Model renamed to: /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/transformer_with_stats.h5
Completed at Τετ 09 Απρ 2025 01:54:55 μμ EEST
=====================================================
Scaler file exists at /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5/scaler.save

=====================================================
All models trained successfully!
Models are saved in /home/dimitris/Impact-xG_prediction_model/forecasting_models_v5
Training completed at Τετ 09 Απρ 2025 01:54:55 μμ EEST
=====================================================
